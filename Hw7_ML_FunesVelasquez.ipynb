{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyN+fsMfWuYiVj2nWF3gGciS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lafunes/Machine_Learning/blob/main/Hw7_ML_FunesVelasquez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yi-ePtIYjsf"
      },
      "outputs": [],
      "source": [
        "cifar10_dir = r'\"C:\\Users\\lfune\\Downloads\\cifar-10-batches-py\"'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Set the directory for the CIFAR-10 dataset\n",
        "cifar10_dir = r'/Users/voeh/Downloads/cifar-10-batches-py'\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=cifar10_dir, train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=cifar10_dir, train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define a Convolutional Neural Network\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)  # 10 classes in CIFAR-10\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 5 * 5)  # Flatten the output for the fully connected layer\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = ConvNet()\n",
        "\n",
        "# Define Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the network\n",
        "start_time = time.time()\n",
        "for epoch in range(300):  # Loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print('Finished Training')\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "\n",
        "# Test the network on the test data\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGqBLzUKsz0f",
        "outputId": "8fd251ab-548e-4fd8-e293-133bfa2a9f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /Users/voeh/Downloads/cifar-10-batches-py/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 28906141.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /Users/voeh/Downloads/cifar-10-batches-py/cifar-10-python.tar.gz to /Users/voeh/Downloads/cifar-10-batches-py\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.136\n",
            "[1,  4000] loss: 1.733\n",
            "[1,  6000] loss: 1.559\n",
            "[1,  8000] loss: 1.455\n",
            "[1, 10000] loss: 1.374\n",
            "[1, 12000] loss: 1.336\n",
            "[2,  2000] loss: 1.224\n",
            "[2,  4000] loss: 1.174\n",
            "[2,  6000] loss: 1.156\n",
            "[2,  8000] loss: 1.111\n",
            "[2, 10000] loss: 1.075\n",
            "[2, 12000] loss: 1.034\n",
            "[3,  2000] loss: 0.947\n",
            "[3,  4000] loss: 0.937\n",
            "[3,  6000] loss: 0.939\n",
            "[3,  8000] loss: 0.929\n",
            "[3, 10000] loss: 0.893\n",
            "[3, 12000] loss: 0.894\n",
            "[4,  2000] loss: 0.780\n",
            "[4,  4000] loss: 0.804\n",
            "[4,  6000] loss: 0.781\n",
            "[4,  8000] loss: 0.810\n",
            "[4, 10000] loss: 0.774\n",
            "[4, 12000] loss: 0.786\n",
            "[5,  2000] loss: 0.645\n",
            "[5,  4000] loss: 0.666\n",
            "[5,  6000] loss: 0.694\n",
            "[5,  8000] loss: 0.693\n",
            "[5, 10000] loss: 0.714\n",
            "[5, 12000] loss: 0.697\n",
            "[6,  2000] loss: 0.548\n",
            "[6,  4000] loss: 0.591\n",
            "[6,  6000] loss: 0.599\n",
            "[6,  8000] loss: 0.623\n",
            "[6, 10000] loss: 0.614\n",
            "[6, 12000] loss: 0.618\n",
            "[7,  2000] loss: 0.476\n",
            "[7,  4000] loss: 0.511\n",
            "[7,  6000] loss: 0.519\n",
            "[7,  8000] loss: 0.518\n",
            "[7, 10000] loss: 0.545\n",
            "[7, 12000] loss: 0.567\n",
            "[8,  2000] loss: 0.402\n",
            "[8,  4000] loss: 0.429\n",
            "[8,  6000] loss: 0.451\n",
            "[8,  8000] loss: 0.468\n",
            "[8, 10000] loss: 0.491\n",
            "[8, 12000] loss: 0.475\n",
            "[9,  2000] loss: 0.352\n",
            "[9,  4000] loss: 0.382\n",
            "[9,  6000] loss: 0.418\n",
            "[9,  8000] loss: 0.404\n",
            "[9, 10000] loss: 0.443\n",
            "[9, 12000] loss: 0.447\n",
            "[10,  2000] loss: 0.307\n",
            "[10,  4000] loss: 0.328\n",
            "[10,  6000] loss: 0.370\n",
            "[10,  8000] loss: 0.384\n",
            "[10, 10000] loss: 0.387\n",
            "[10, 12000] loss: 0.405\n",
            "[11,  2000] loss: 0.252\n",
            "[11,  4000] loss: 0.284\n",
            "[11,  6000] loss: 0.328\n",
            "[11,  8000] loss: 0.356\n",
            "[11, 10000] loss: 0.362\n",
            "[11, 12000] loss: 0.370\n",
            "[12,  2000] loss: 0.246\n",
            "[12,  4000] loss: 0.250\n",
            "[12,  6000] loss: 0.313\n",
            "[12,  8000] loss: 0.300\n",
            "[12, 10000] loss: 0.320\n",
            "[12, 12000] loss: 0.343\n",
            "[13,  2000] loss: 0.204\n",
            "[13,  4000] loss: 0.246\n",
            "[13,  6000] loss: 0.268\n",
            "[13,  8000] loss: 0.281\n",
            "[13, 10000] loss: 0.269\n",
            "[13, 12000] loss: 0.301\n",
            "[14,  2000] loss: 0.187\n",
            "[14,  4000] loss: 0.213\n",
            "[14,  6000] loss: 0.268\n",
            "[14,  8000] loss: 0.281\n",
            "[14, 10000] loss: 0.259\n",
            "[14, 12000] loss: 0.285\n",
            "[15,  2000] loss: 0.172\n",
            "[15,  4000] loss: 0.212\n",
            "[15,  6000] loss: 0.240\n",
            "[15,  8000] loss: 0.231\n",
            "[15, 10000] loss: 0.224\n",
            "[15, 12000] loss: 0.270\n",
            "[16,  2000] loss: 0.150\n",
            "[16,  4000] loss: 0.169\n",
            "[16,  6000] loss: 0.237\n",
            "[16,  8000] loss: 0.228\n",
            "[16, 10000] loss: 0.257\n",
            "[16, 12000] loss: 0.259\n",
            "[17,  2000] loss: 0.139\n",
            "[17,  4000] loss: 0.184\n",
            "[17,  6000] loss: 0.219\n",
            "[17,  8000] loss: 0.214\n",
            "[17, 10000] loss: 0.219\n",
            "[17, 12000] loss: 0.238\n",
            "[18,  2000] loss: 0.145\n",
            "[18,  4000] loss: 0.174\n",
            "[18,  6000] loss: 0.181\n",
            "[18,  8000] loss: 0.196\n",
            "[18, 10000] loss: 0.215\n",
            "[18, 12000] loss: 0.230\n",
            "[19,  2000] loss: 0.136\n",
            "[19,  4000] loss: 0.154\n",
            "[19,  6000] loss: 0.166\n",
            "[19,  8000] loss: 0.196\n",
            "[19, 10000] loss: 0.208\n",
            "[19, 12000] loss: 0.225\n",
            "[20,  2000] loss: 0.152\n",
            "[20,  4000] loss: 0.140\n",
            "[20,  6000] loss: 0.145\n",
            "[20,  8000] loss: 0.190\n",
            "[20, 10000] loss: 0.203\n",
            "[20, 12000] loss: 0.190\n",
            "[21,  2000] loss: 0.113\n",
            "[21,  4000] loss: 0.131\n",
            "[21,  6000] loss: 0.174\n",
            "[21,  8000] loss: 0.208\n",
            "[21, 10000] loss: 0.184\n",
            "[21, 12000] loss: 0.194\n",
            "[22,  2000] loss: 0.111\n",
            "[22,  4000] loss: 0.125\n",
            "[22,  6000] loss: 0.181\n",
            "[22,  8000] loss: 0.181\n",
            "[22, 10000] loss: 0.179\n",
            "[22, 12000] loss: 0.202\n",
            "[23,  2000] loss: 0.100\n",
            "[23,  4000] loss: 0.155\n",
            "[23,  6000] loss: 0.136\n",
            "[23,  8000] loss: 0.195\n",
            "[23, 10000] loss: 0.165\n",
            "[23, 12000] loss: 0.160\n",
            "[24,  2000] loss: 0.115\n",
            "[24,  4000] loss: 0.153\n",
            "[24,  6000] loss: 0.156\n",
            "[24,  8000] loss: 0.161\n",
            "[24, 10000] loss: 0.178\n",
            "[24, 12000] loss: 0.202\n",
            "[25,  2000] loss: 0.131\n",
            "[25,  4000] loss: 0.143\n",
            "[25,  6000] loss: 0.136\n",
            "[25,  8000] loss: 0.180\n",
            "[25, 10000] loss: 0.162\n",
            "[25, 12000] loss: 0.168\n",
            "[26,  2000] loss: 0.102\n",
            "[26,  4000] loss: 0.148\n",
            "[26,  6000] loss: 0.143\n",
            "[26,  8000] loss: 0.146\n",
            "[26, 10000] loss: 0.155\n",
            "[26, 12000] loss: 0.159\n",
            "[27,  2000] loss: 0.109\n",
            "[27,  4000] loss: 0.143\n",
            "[27,  6000] loss: 0.131\n",
            "[27,  8000] loss: 0.136\n",
            "[27, 10000] loss: 0.178\n",
            "[27, 12000] loss: 0.157\n",
            "[28,  2000] loss: 0.104\n",
            "[28,  4000] loss: 0.127\n",
            "[28,  6000] loss: 0.170\n",
            "[28,  8000] loss: 0.150\n",
            "[28, 10000] loss: 0.162\n",
            "[28, 12000] loss: 0.189\n",
            "[29,  2000] loss: 0.099\n",
            "[29,  4000] loss: 0.147\n",
            "[29,  6000] loss: 0.126\n",
            "[29,  8000] loss: 0.164\n",
            "[29, 10000] loss: 0.154\n",
            "[29, 12000] loss: 0.143\n",
            "[30,  2000] loss: 0.120\n",
            "[30,  4000] loss: 0.110\n",
            "[30,  6000] loss: 0.136\n",
            "[30,  8000] loss: 0.178\n",
            "[30, 10000] loss: 0.163\n",
            "[30, 12000] loss: 0.147\n",
            "[31,  2000] loss: 0.107\n",
            "[31,  4000] loss: 0.125\n",
            "[31,  6000] loss: 0.139\n",
            "[31,  8000] loss: 0.177\n",
            "[31, 10000] loss: 0.150\n",
            "[31, 12000] loss: 0.159\n",
            "[32,  2000] loss: 0.088\n",
            "[32,  4000] loss: 0.139\n",
            "[32,  6000] loss: 0.123\n",
            "[32,  8000] loss: 0.149\n",
            "[32, 10000] loss: 0.149\n",
            "[32, 12000] loss: 0.154\n",
            "[33,  2000] loss: 0.086\n",
            "[33,  4000] loss: 0.113\n",
            "[33,  6000] loss: 0.122\n",
            "[33,  8000] loss: 0.176\n",
            "[33, 10000] loss: 0.168\n",
            "[33, 12000] loss: 0.163\n",
            "[34,  2000] loss: 0.153\n",
            "[34,  4000] loss: 0.123\n",
            "[34,  6000] loss: 0.119\n",
            "[34,  8000] loss: 0.137\n",
            "[34, 10000] loss: 0.173\n",
            "[34, 12000] loss: 0.161\n",
            "[35,  2000] loss: 0.094\n",
            "[35,  4000] loss: 0.154\n",
            "[35,  6000] loss: 0.112\n",
            "[35,  8000] loss: 0.100\n",
            "[35, 10000] loss: 0.103\n",
            "[35, 12000] loss: 0.144\n",
            "[36,  2000] loss: 0.100\n",
            "[36,  4000] loss: 0.109\n",
            "[36,  6000] loss: 0.152\n",
            "[36,  8000] loss: 0.151\n",
            "[36, 10000] loss: 0.158\n",
            "[36, 12000] loss: 0.165\n",
            "[37,  2000] loss: 0.097\n",
            "[37,  4000] loss: 0.132\n",
            "[37,  6000] loss: 0.124\n",
            "[37,  8000] loss: 0.152\n",
            "[37, 10000] loss: 0.178\n",
            "[37, 12000] loss: 0.143\n",
            "[38,  2000] loss: 0.112\n",
            "[38,  4000] loss: 0.098\n",
            "[38,  6000] loss: 0.121\n",
            "[38,  8000] loss: 0.158\n",
            "[38, 10000] loss: 0.156\n",
            "[38, 12000] loss: 0.162\n",
            "[39,  2000] loss: 0.121\n",
            "[39,  4000] loss: 0.135\n",
            "[39,  6000] loss: 0.124\n",
            "[39,  8000] loss: 0.140\n",
            "[39, 10000] loss: 0.151\n",
            "[39, 12000] loss: 0.162\n",
            "[40,  2000] loss: 0.105\n",
            "[40,  4000] loss: 0.113\n",
            "[40,  6000] loss: 0.164\n",
            "[40,  8000] loss: 0.129\n",
            "[40, 10000] loss: 0.153\n",
            "[40, 12000] loss: 0.216\n",
            "[41,  2000] loss: 0.113\n",
            "[41,  4000] loss: 0.109\n",
            "[41,  6000] loss: 0.190\n",
            "[41,  8000] loss: 0.158\n",
            "[41, 10000] loss: 0.183\n",
            "[41, 12000] loss: 0.177\n",
            "[42,  2000] loss: 0.100\n",
            "[42,  4000] loss: 0.121\n",
            "[42,  6000] loss: 0.106\n",
            "[42,  8000] loss: 0.132\n",
            "[42, 10000] loss: 0.131\n",
            "[42, 12000] loss: 0.171\n",
            "[43,  2000] loss: 0.110\n",
            "[43,  4000] loss: 0.140\n",
            "[43,  6000] loss: 0.154\n",
            "[43,  8000] loss: 0.160\n",
            "[43, 10000] loss: 0.169\n",
            "[43, 12000] loss: 0.140\n",
            "[44,  2000] loss: 0.113\n",
            "[44,  4000] loss: 0.102\n",
            "[44,  6000] loss: 0.131\n",
            "[44,  8000] loss: 0.133\n",
            "[44, 10000] loss: 0.160\n",
            "[44, 12000] loss: 0.161\n",
            "[45,  2000] loss: 0.105\n",
            "[45,  4000] loss: 0.104\n",
            "[45,  6000] loss: 0.100\n",
            "[45,  8000] loss: 0.189\n",
            "[45, 10000] loss: 0.182\n",
            "[45, 12000] loss: 0.164\n",
            "[46,  2000] loss: 0.107\n",
            "[46,  4000] loss: 0.140\n",
            "[46,  6000] loss: 0.143\n",
            "[46,  8000] loss: 0.131\n",
            "[46, 10000] loss: 0.134\n",
            "[46, 12000] loss: 0.176\n",
            "[47,  2000] loss: 0.113\n",
            "[47,  4000] loss: 0.137\n",
            "[47,  6000] loss: 0.134\n",
            "[47,  8000] loss: 0.154\n",
            "[47, 10000] loss: 0.187\n",
            "[47, 12000] loss: 0.182\n",
            "[48,  2000] loss: 0.097\n",
            "[48,  4000] loss: 0.105\n",
            "[48,  6000] loss: 0.143\n",
            "[48,  8000] loss: 0.142\n",
            "[48, 10000] loss: 0.171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "# Set the directory for the CIFAR-10 dataset\n",
        "#cifar10_dir = '/Users/voeh/Downloads/cifar-10-batches-py'\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=cifar10_dir, train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=cifar10_dir, train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define a CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 5)\n",
        "        self.fc1 = nn.Linear(128 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 128 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = CNN()\n",
        "\n",
        "# Define Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the network\n",
        "start_time = time.time()\n",
        "for epoch in range(300):  # Loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print('Finished Training')\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "\n",
        "# Test the network on the test data\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "1xbTwtXbZte5",
        "outputId": "7ba3d057-8bec-4b8d-b924-b0328e634a1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to \"C:\\Users\\lfune\\Downloads\\cifar-10-batches-py\"/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 30014456.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting \"C:\\Users\\lfune\\Downloads\\cifar-10-batches-py\"/cifar-10-python.tar.gz to \"C:\\Users\\lfune\\Downloads\\cifar-10-batches-py\"\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.050\n",
            "[1,  4000] loss: 1.675\n",
            "[1,  6000] loss: 1.506\n",
            "[1,  8000] loss: 1.413\n",
            "[1, 10000] loss: 1.341\n",
            "[1, 12000] loss: 1.249\n",
            "[2,  2000] loss: 1.160\n",
            "[2,  4000] loss: 1.111\n",
            "[2,  6000] loss: 1.054\n",
            "[2,  8000] loss: 1.030\n",
            "[2, 10000] loss: 1.000\n",
            "[2, 12000] loss: 0.991\n",
            "[3,  2000] loss: 0.878\n",
            "[3,  4000] loss: 0.837\n",
            "[3,  6000] loss: 0.841\n",
            "[3,  8000] loss: 0.837\n",
            "[3, 10000] loss: 0.841\n",
            "[3, 12000] loss: 0.823\n",
            "[4,  2000] loss: 0.691\n",
            "[4,  4000] loss: 0.714\n",
            "[4,  6000] loss: 0.700\n",
            "[4,  8000] loss: 0.719\n",
            "[4, 10000] loss: 0.701\n",
            "[4, 12000] loss: 0.713\n",
            "[5,  2000] loss: 0.560\n",
            "[5,  4000] loss: 0.579\n",
            "[5,  6000] loss: 0.582\n",
            "[5,  8000] loss: 0.608\n",
            "[5, 10000] loss: 0.609\n",
            "[5, 12000] loss: 0.599\n",
            "[6,  2000] loss: 0.450\n",
            "[6,  4000] loss: 0.476\n",
            "[6,  6000] loss: 0.465\n",
            "[6,  8000] loss: 0.506\n",
            "[6, 10000] loss: 0.522\n",
            "[6, 12000] loss: 0.532\n",
            "[7,  2000] loss: 0.356\n",
            "[7,  4000] loss: 0.395\n",
            "[7,  6000] loss: 0.418\n",
            "[7,  8000] loss: 0.421\n",
            "[7, 10000] loss: 0.443\n",
            "[7, 12000] loss: 0.448\n",
            "[8,  2000] loss: 0.306\n",
            "[8,  4000] loss: 0.302\n",
            "[8,  6000] loss: 0.336\n",
            "[8,  8000] loss: 0.356\n",
            "[8, 10000] loss: 0.401\n",
            "[8, 12000] loss: 0.372\n",
            "[9,  2000] loss: 0.236\n",
            "[9,  4000] loss: 0.272\n",
            "[9,  6000] loss: 0.274\n",
            "[9,  8000] loss: 0.312\n",
            "[9, 10000] loss: 0.318\n",
            "[9, 12000] loss: 0.330\n",
            "[10,  2000] loss: 0.200\n",
            "[10,  4000] loss: 0.219\n",
            "[10,  6000] loss: 0.259\n",
            "[10,  8000] loss: 0.272\n",
            "[10, 10000] loss: 0.261\n",
            "[10, 12000] loss: 0.274\n",
            "[11,  2000] loss: 0.155\n",
            "[11,  4000] loss: 0.194\n",
            "[11,  6000] loss: 0.198\n",
            "[11,  8000] loss: 0.213\n",
            "[11, 10000] loss: 0.236\n",
            "[11, 12000] loss: 0.256\n",
            "[12,  2000] loss: 0.138\n",
            "[12,  4000] loss: 0.149\n",
            "[12,  6000] loss: 0.192\n",
            "[12,  8000] loss: 0.189\n",
            "[12, 10000] loss: 0.212\n",
            "[12, 12000] loss: 0.233\n",
            "[13,  2000] loss: 0.123\n",
            "[13,  4000] loss: 0.154\n",
            "[13,  6000] loss: 0.201\n",
            "[13,  8000] loss: 0.167\n",
            "[13, 10000] loss: 0.192\n",
            "[13, 12000] loss: 0.211\n",
            "[14,  2000] loss: 0.121\n",
            "[14,  4000] loss: 0.119\n",
            "[14,  6000] loss: 0.160\n",
            "[14,  8000] loss: 0.146\n",
            "[14, 10000] loss: 0.172\n",
            "[14, 12000] loss: 0.166\n",
            "[15,  2000] loss: 0.097\n",
            "[15,  4000] loss: 0.114\n",
            "[15,  6000] loss: 0.123\n",
            "[15,  8000] loss: 0.120\n",
            "[15, 10000] loss: 0.132\n",
            "[15, 12000] loss: 0.178\n",
            "[16,  2000] loss: 0.106\n",
            "[16,  4000] loss: 0.119\n",
            "[16,  6000] loss: 0.140\n",
            "[16,  8000] loss: 0.127\n",
            "[16, 10000] loss: 0.133\n",
            "[16, 12000] loss: 0.136\n",
            "[17,  2000] loss: 0.099\n",
            "[17,  4000] loss: 0.092\n",
            "[17,  6000] loss: 0.102\n",
            "[17,  8000] loss: 0.138\n",
            "[17, 10000] loss: 0.145\n",
            "[17, 12000] loss: 0.121\n",
            "[18,  2000] loss: 0.087\n",
            "[18,  4000] loss: 0.103\n",
            "[18,  6000] loss: 0.098\n",
            "[18,  8000] loss: 0.108\n",
            "[18, 10000] loss: 0.107\n",
            "[18, 12000] loss: 0.112\n",
            "[19,  2000] loss: 0.075\n",
            "[19,  4000] loss: 0.085\n",
            "[19,  6000] loss: 0.100\n",
            "[19,  8000] loss: 0.090\n",
            "[19, 10000] loss: 0.109\n",
            "[19, 12000] loss: 0.087\n",
            "[20,  2000] loss: 0.073\n",
            "[20,  4000] loss: 0.063\n",
            "[20,  6000] loss: 0.088\n",
            "[20,  8000] loss: 0.083\n",
            "[20, 10000] loss: 0.088\n",
            "[20, 12000] loss: 0.109\n",
            "[21,  2000] loss: 0.070\n",
            "[21,  4000] loss: 0.072\n",
            "[21,  6000] loss: 0.085\n",
            "[21,  8000] loss: 0.094\n",
            "[21, 10000] loss: 0.118\n",
            "[21, 12000] loss: 0.088\n",
            "[22,  2000] loss: 0.064\n",
            "[22,  4000] loss: 0.084\n",
            "[22,  6000] loss: 0.104\n",
            "[22,  8000] loss: 0.081\n",
            "[22, 10000] loss: 0.078\n",
            "[22, 12000] loss: 0.089\n",
            "[23,  2000] loss: 0.076\n",
            "[23,  4000] loss: 0.082\n",
            "[23,  6000] loss: 0.096\n",
            "[23,  8000] loss: 0.091\n",
            "[23, 10000] loss: 0.086\n",
            "[23, 12000] loss: 0.090\n",
            "[24,  2000] loss: 0.050\n",
            "[24,  4000] loss: 0.061\n",
            "[24,  6000] loss: 0.066\n",
            "[24,  8000] loss: 0.083\n",
            "[24, 10000] loss: 0.093\n",
            "[24, 12000] loss: 0.079\n",
            "[25,  2000] loss: 0.050\n",
            "[25,  4000] loss: 0.062\n",
            "[25,  6000] loss: 0.082\n",
            "[25,  8000] loss: 0.092\n",
            "[25, 10000] loss: 0.061\n",
            "[25, 12000] loss: 0.080\n",
            "[26,  2000] loss: 0.051\n",
            "[26,  4000] loss: 0.087\n",
            "[26,  6000] loss: 0.070\n",
            "[26,  8000] loss: 0.076\n",
            "[26, 10000] loss: 0.071\n",
            "[26, 12000] loss: 0.091\n",
            "[27,  2000] loss: 0.053\n",
            "[27,  4000] loss: 0.040\n",
            "[27,  6000] loss: 0.055\n",
            "[27,  8000] loss: 0.073\n",
            "[27, 10000] loss: 0.091\n",
            "[27, 12000] loss: 0.081\n",
            "[28,  2000] loss: 0.045\n",
            "[28,  4000] loss: 0.057\n",
            "[28,  6000] loss: 0.056\n",
            "[28,  8000] loss: 0.048\n",
            "[28, 10000] loss: 0.074\n",
            "[28, 12000] loss: 0.089\n",
            "[29,  2000] loss: 0.044\n",
            "[29,  4000] loss: 0.048\n",
            "[29,  6000] loss: 0.066\n",
            "[29,  8000] loss: 0.077\n",
            "[29, 10000] loss: 0.080\n",
            "[29, 12000] loss: 0.075\n",
            "[30,  2000] loss: 0.059\n",
            "[30,  4000] loss: 0.044\n",
            "[30,  6000] loss: 0.057\n",
            "[30,  8000] loss: 0.073\n",
            "[30, 10000] loss: 0.081\n",
            "[30, 12000] loss: 0.089\n",
            "[31,  2000] loss: 0.040\n",
            "[31,  4000] loss: 0.055\n",
            "[31,  6000] loss: 0.060\n",
            "[31,  8000] loss: 0.067\n",
            "[31, 10000] loss: 0.045\n",
            "[31, 12000] loss: 0.077\n",
            "[32,  2000] loss: 0.058\n",
            "[32,  4000] loss: 0.038\n",
            "[32,  6000] loss: 0.080\n",
            "[32,  8000] loss: 0.064\n",
            "[32, 10000] loss: 0.078\n",
            "[32, 12000] loss: 0.079\n",
            "[33,  2000] loss: 0.049\n",
            "[33,  4000] loss: 0.037\n",
            "[33,  6000] loss: 0.056\n",
            "[33,  8000] loss: 0.059\n",
            "[33, 10000] loss: 0.058\n",
            "[33, 12000] loss: 0.077\n",
            "[34,  2000] loss: 0.046\n",
            "[34,  4000] loss: 0.051\n",
            "[34,  6000] loss: 0.063\n",
            "[34,  8000] loss: 0.056\n",
            "[34, 10000] loss: 0.076\n",
            "[34, 12000] loss: 0.074\n",
            "[35,  2000] loss: 0.041\n",
            "[35,  4000] loss: 0.060\n",
            "[35,  6000] loss: 0.043\n",
            "[35,  8000] loss: 0.046\n",
            "[35, 10000] loss: 0.048\n",
            "[35, 12000] loss: 0.055\n",
            "[36,  2000] loss: 0.049\n",
            "[36,  4000] loss: 0.056\n",
            "[36,  6000] loss: 0.058\n",
            "[36,  8000] loss: 0.072\n",
            "[36, 10000] loss: 0.099\n",
            "[36, 12000] loss: 0.068\n",
            "[37,  2000] loss: 0.033\n",
            "[37,  4000] loss: 0.034\n",
            "[37,  6000] loss: 0.053\n",
            "[37,  8000] loss: 0.071\n",
            "[37, 10000] loss: 0.054\n",
            "[37, 12000] loss: 0.075\n",
            "[38,  2000] loss: 0.050\n",
            "[38,  4000] loss: 0.069\n",
            "[38,  6000] loss: 0.054\n",
            "[38,  8000] loss: 0.057\n",
            "[38, 10000] loss: 0.056\n",
            "[38, 12000] loss: 0.066\n",
            "[39,  2000] loss: 0.033\n",
            "[39,  4000] loss: 0.042\n",
            "[39,  6000] loss: 0.062\n",
            "[39,  8000] loss: 0.046\n",
            "[39, 10000] loss: 0.074\n",
            "[39, 12000] loss: 0.060\n",
            "[40,  2000] loss: 0.048\n",
            "[40,  4000] loss: 0.040\n",
            "[40,  6000] loss: 0.049\n",
            "[40,  8000] loss: 0.055\n",
            "[40, 10000] loss: 0.061\n",
            "[40, 12000] loss: 0.050\n",
            "[41,  2000] loss: 0.042\n",
            "[41,  4000] loss: 0.022\n",
            "[41,  6000] loss: 0.037\n",
            "[41,  8000] loss: 0.046\n",
            "[41, 10000] loss: 0.043\n",
            "[41, 12000] loss: 0.083\n",
            "[42,  2000] loss: 0.042\n",
            "[42,  4000] loss: 0.044\n",
            "[42,  6000] loss: 0.067\n",
            "[42,  8000] loss: 0.071\n",
            "[42, 10000] loss: 0.048\n",
            "[42, 12000] loss: 0.060\n",
            "[43,  2000] loss: 0.035\n",
            "[43,  4000] loss: 0.041\n",
            "[43,  6000] loss: 0.083\n",
            "[43,  8000] loss: 0.063\n",
            "[43, 10000] loss: 0.087\n",
            "[43, 12000] loss: 0.069\n",
            "[44,  2000] loss: 0.037\n",
            "[44,  4000] loss: 0.051\n",
            "[44,  6000] loss: 0.060\n",
            "[44,  8000] loss: 0.068\n",
            "[44, 10000] loss: 0.067\n",
            "[44, 12000] loss: 0.052\n",
            "[45,  2000] loss: 0.032\n",
            "[45,  4000] loss: 0.061\n",
            "[45,  6000] loss: 0.059\n",
            "[45,  8000] loss: 0.039\n",
            "[45, 10000] loss: 0.050\n",
            "[45, 12000] loss: 0.067\n",
            "[46,  2000] loss: 0.040\n",
            "[46,  4000] loss: 0.047\n",
            "[46,  6000] loss: 0.036\n",
            "[46,  8000] loss: 0.048\n",
            "[46, 10000] loss: 0.061\n",
            "[46, 12000] loss: 0.071\n",
            "[47,  2000] loss: 0.038\n",
            "[47,  4000] loss: 0.038\n",
            "[47,  6000] loss: 0.025\n",
            "[47,  8000] loss: 0.058\n",
            "[47, 10000] loss: 0.060\n",
            "[47, 12000] loss: 0.047\n",
            "[48,  2000] loss: 0.037\n",
            "[48,  4000] loss: 0.033\n",
            "[48,  6000] loss: 0.041\n",
            "[48,  8000] loss: 0.055\n",
            "[48, 10000] loss: 0.039\n",
            "[48, 12000] loss: 0.056\n",
            "[49,  2000] loss: 0.062\n",
            "[49,  4000] loss: 0.041\n",
            "[49,  6000] loss: 0.064\n",
            "[49,  8000] loss: 0.067\n",
            "[49, 10000] loss: 0.068\n",
            "[49, 12000] loss: 0.064\n",
            "[50,  2000] loss: 0.045\n",
            "[50,  4000] loss: 0.035\n",
            "[50,  6000] loss: 0.049\n",
            "[50,  8000] loss: 0.046\n",
            "[50, 10000] loss: 0.084\n",
            "[50, 12000] loss: 0.087\n",
            "[51,  2000] loss: 0.032\n",
            "[51,  4000] loss: 0.043\n",
            "[51,  6000] loss: 0.021\n",
            "[51,  8000] loss: 0.041\n",
            "[51, 10000] loss: 0.050\n",
            "[51, 12000] loss: 0.074\n",
            "[52,  2000] loss: 0.043\n",
            "[52,  4000] loss: 0.039\n",
            "[52,  6000] loss: 0.048\n",
            "[52,  8000] loss: 0.039\n",
            "[52, 10000] loss: 0.044\n",
            "[52, 12000] loss: 0.046\n",
            "[53,  2000] loss: 0.039\n",
            "[53,  4000] loss: 0.034\n",
            "[53,  6000] loss: 0.026\n",
            "[53,  8000] loss: 0.039\n",
            "[53, 10000] loss: 0.058\n",
            "[53, 12000] loss: 0.069\n",
            "[54,  2000] loss: 0.043\n",
            "[54,  4000] loss: 0.060\n",
            "[54,  6000] loss: 0.056\n",
            "[54,  8000] loss: 0.047\n",
            "[54, 10000] loss: 0.035\n",
            "[54, 12000] loss: 0.054\n",
            "[55,  2000] loss: 0.036\n",
            "[55,  4000] loss: 0.037\n",
            "[55,  6000] loss: 0.028\n",
            "[55,  8000] loss: 0.058\n",
            "[55, 10000] loss: 0.058\n",
            "[55, 12000] loss: 0.038\n",
            "[56,  2000] loss: 0.042\n",
            "[56,  4000] loss: 0.053\n",
            "[56,  6000] loss: 0.050\n",
            "[56,  8000] loss: 0.051\n",
            "[56, 10000] loss: 0.055\n",
            "[56, 12000] loss: 0.078\n",
            "[57,  2000] loss: 0.054\n",
            "[57,  4000] loss: 0.043\n",
            "[57,  6000] loss: 0.039\n",
            "[57,  8000] loss: 0.039\n",
            "[57, 10000] loss: 0.061\n",
            "[57, 12000] loss: 0.043\n",
            "[58,  2000] loss: 0.045\n",
            "[58,  4000] loss: 0.079\n",
            "[58,  6000] loss: 0.077\n",
            "[58,  8000] loss: 0.050\n",
            "[58, 10000] loss: 0.054\n",
            "[58, 12000] loss: 0.062\n",
            "[59,  2000] loss: 0.032\n",
            "[59,  4000] loss: 0.035\n",
            "[59,  6000] loss: 0.035\n",
            "[59,  8000] loss: 0.027\n",
            "[59, 10000] loss: 0.027\n",
            "[59, 12000] loss: 0.046\n",
            "[60,  2000] loss: 0.028\n",
            "[60,  4000] loss: 0.036\n",
            "[60,  6000] loss: 0.037\n",
            "[60,  8000] loss: 0.064\n",
            "[60, 10000] loss: 0.071\n",
            "[60, 12000] loss: 0.064\n",
            "[61,  2000] loss: 0.044\n",
            "[61,  4000] loss: 0.060\n",
            "[61,  6000] loss: 0.062\n",
            "[61,  8000] loss: 0.075\n",
            "[61, 10000] loss: 0.081\n",
            "[61, 12000] loss: 0.072\n",
            "[62,  2000] loss: 0.034\n",
            "[62,  4000] loss: 0.051\n",
            "[62,  6000] loss: 0.050\n",
            "[62,  8000] loss: 0.076\n",
            "[62, 10000] loss: 0.088\n",
            "[62, 12000] loss: 0.073\n",
            "[63,  2000] loss: 0.040\n",
            "[63,  4000] loss: 0.035\n",
            "[63,  6000] loss: 0.036\n",
            "[63,  8000] loss: 0.037\n",
            "[63, 10000] loss: 0.073\n",
            "[63, 12000] loss: 0.059\n",
            "[64,  2000] loss: 0.028\n",
            "[64,  4000] loss: 0.032\n",
            "[64,  6000] loss: 0.028\n",
            "[64,  8000] loss: 0.021\n",
            "[64, 10000] loss: 0.045\n",
            "[64, 12000] loss: 0.052\n",
            "[65,  2000] loss: 0.033\n",
            "[65,  4000] loss: 0.022\n",
            "[65,  6000] loss: 0.024\n",
            "[65,  8000] loss: 0.048\n",
            "[65, 10000] loss: 0.050\n",
            "[65, 12000] loss: 0.067\n",
            "[66,  2000] loss: 0.055\n",
            "[66,  4000] loss: 0.070\n",
            "[66,  6000] loss: 0.069\n",
            "[66,  8000] loss: 0.062\n",
            "[66, 10000] loss: 0.067\n",
            "[66, 12000] loss: 0.076\n",
            "[67,  2000] loss: 0.053\n",
            "[67,  4000] loss: 0.068\n",
            "[67,  6000] loss: 0.053\n",
            "[67,  8000] loss: 0.081\n",
            "[67, 10000] loss: 0.074\n",
            "[67, 12000] loss: 0.075\n",
            "[68,  2000] loss: 0.034\n",
            "[68,  4000] loss: 0.039\n",
            "[68,  6000] loss: 0.052\n",
            "[68,  8000] loss: 0.044\n",
            "[68, 10000] loss: 0.039\n",
            "[68, 12000] loss: 0.069\n",
            "[69,  2000] loss: 0.043\n",
            "[69,  4000] loss: 0.030\n",
            "[69,  6000] loss: 0.037\n",
            "[69,  8000] loss: 0.065\n",
            "[69, 10000] loss: 0.048\n",
            "[69, 12000] loss: 0.088\n",
            "[70,  2000] loss: 0.043\n",
            "[70,  4000] loss: 0.050\n",
            "[70,  6000] loss: 0.050\n",
            "[70,  8000] loss: 0.040\n",
            "[70, 10000] loss: 0.053\n",
            "[70, 12000] loss: 0.048\n",
            "[71,  2000] loss: 0.026\n",
            "[71,  4000] loss: 0.052\n",
            "[71,  6000] loss: 0.054\n",
            "[71,  8000] loss: 0.049\n",
            "[71, 10000] loss: 0.065\n",
            "[71, 12000] loss: 0.062\n",
            "[72,  2000] loss: 0.048\n",
            "[72,  4000] loss: 0.078\n",
            "[72,  6000] loss: 0.054\n",
            "[72,  8000] loss: 0.060\n",
            "[72, 10000] loss: 0.069\n",
            "[72, 12000] loss: 0.061\n",
            "[73,  2000] loss: 0.045\n",
            "[73,  4000] loss: 0.051\n",
            "[73,  6000] loss: 0.041\n",
            "[73,  8000] loss: 0.031\n",
            "[73, 10000] loss: 0.049\n",
            "[73, 12000] loss: 0.069\n",
            "[74,  2000] loss: 0.064\n",
            "[74,  4000] loss: 0.032\n",
            "[74,  6000] loss: 0.043\n",
            "[74,  8000] loss: 0.057\n",
            "[74, 10000] loss: 0.066\n",
            "[74, 12000] loss: 0.054\n",
            "[75,  2000] loss: 0.036\n",
            "[75,  4000] loss: 0.037\n",
            "[75,  6000] loss: 0.038\n",
            "[75,  8000] loss: 0.041\n",
            "[75, 10000] loss: 0.037\n",
            "[75, 12000] loss: 0.043\n",
            "[76,  2000] loss: 0.024\n",
            "[76,  4000] loss: 0.033\n",
            "[76,  6000] loss: 0.036\n",
            "[76,  8000] loss: 0.044\n",
            "[76, 10000] loss: 0.073\n",
            "[76, 12000] loss: 0.054\n",
            "[77,  2000] loss: 0.074\n",
            "[77,  4000] loss: 0.042\n",
            "[77,  6000] loss: 0.044\n",
            "[77,  8000] loss: 0.050\n",
            "[77, 10000] loss: 0.045\n",
            "[77, 12000] loss: 0.074\n",
            "[78,  2000] loss: 0.026\n",
            "[78,  4000] loss: 0.042\n",
            "[78,  6000] loss: 0.082\n",
            "[78,  8000] loss: 0.095\n",
            "[78, 10000] loss: 0.063\n",
            "[78, 12000] loss: 0.053\n",
            "[79,  2000] loss: 0.027\n",
            "[79,  4000] loss: 0.082\n",
            "[79,  6000] loss: 0.071\n",
            "[79,  8000] loss: 0.090\n",
            "[79, 10000] loss: 0.076\n",
            "[79, 12000] loss: 0.097\n",
            "[80,  2000] loss: 0.050\n",
            "[80,  4000] loss: 0.060\n",
            "[80,  6000] loss: 0.094\n",
            "[80,  8000] loss: 0.073\n",
            "[80, 10000] loss: 0.058\n",
            "[80, 12000] loss: 0.061\n",
            "[81,  2000] loss: 0.039\n",
            "[81,  4000] loss: 0.038\n",
            "[81,  6000] loss: 0.030\n",
            "[81,  8000] loss: 0.041\n",
            "[81, 10000] loss: 0.048\n",
            "[81, 12000] loss: 0.071\n",
            "[82,  2000] loss: 0.047\n",
            "[82,  4000] loss: 0.086\n",
            "[82,  6000] loss: 0.064\n",
            "[82,  8000] loss: 0.102\n",
            "[82, 10000] loss: 0.045\n",
            "[82, 12000] loss: 0.054\n",
            "[83,  2000] loss: 0.046\n",
            "[83,  4000] loss: 0.044\n",
            "[83,  6000] loss: 0.063\n",
            "[83,  8000] loss: 0.077\n",
            "[83, 10000] loss: 0.073\n",
            "[83, 12000] loss: 0.045\n",
            "[84,  2000] loss: 0.052\n",
            "[84,  4000] loss: 0.084\n",
            "[84,  6000] loss: 0.078\n",
            "[84,  8000] loss: 0.085\n",
            "[84, 10000] loss: 0.075\n",
            "[84, 12000] loss: 0.063\n",
            "[85,  2000] loss: 0.029\n",
            "[85,  4000] loss: 0.086\n",
            "[85,  6000] loss: 0.066\n",
            "[85,  8000] loss: 0.066\n",
            "[85, 10000] loss: 0.081\n",
            "[85, 12000] loss: 0.080\n",
            "[86,  2000] loss: 0.070\n",
            "[86,  4000] loss: 0.054\n",
            "[86,  6000] loss: 0.064\n",
            "[86,  8000] loss: 0.070\n",
            "[86, 10000] loss: 0.058\n",
            "[86, 12000] loss: 0.078\n",
            "[87,  2000] loss: 0.048\n",
            "[87,  4000] loss: 0.069\n",
            "[87,  6000] loss: 0.055\n",
            "[87,  8000] loss: 0.065\n",
            "[87, 10000] loss: 0.076\n",
            "[87, 12000] loss: 0.074\n",
            "[88,  2000] loss: 0.050\n",
            "[88,  4000] loss: 0.031\n",
            "[88,  6000] loss: 0.074\n",
            "[88,  8000] loss: 0.055\n",
            "[88, 10000] loss: 0.089\n",
            "[88, 12000] loss: 0.079\n",
            "[89,  2000] loss: 0.055\n",
            "[89,  4000] loss: 0.094\n",
            "[89,  6000] loss: 0.065\n",
            "[89,  8000] loss: 0.061\n",
            "[89, 10000] loss: 0.056\n",
            "[89, 12000] loss: 0.067\n",
            "[90,  2000] loss: 0.074\n",
            "[90,  4000] loss: 0.078\n",
            "[90,  6000] loss: 0.111\n",
            "[90,  8000] loss: 0.141\n",
            "[90, 10000] loss: 0.090\n",
            "[90, 12000] loss: 0.074\n",
            "[91,  2000] loss: 0.062\n",
            "[91,  4000] loss: 0.070\n",
            "[91,  6000] loss: 0.071\n",
            "[91,  8000] loss: 0.072\n",
            "[91, 10000] loss: 0.096\n",
            "[91, 12000] loss: 0.078\n",
            "[92,  2000] loss: 0.061\n",
            "[92,  4000] loss: 0.093\n",
            "[92,  6000] loss: 0.083\n",
            "[92,  8000] loss: 0.062\n",
            "[92, 10000] loss: 0.066\n",
            "[92, 12000] loss: 0.079\n",
            "[93,  2000] loss: 0.045\n",
            "[93,  4000] loss: 0.060\n",
            "[93,  6000] loss: 0.060\n",
            "[93,  8000] loss: 0.089\n",
            "[93, 10000] loss: 0.122\n",
            "[93, 12000] loss: 0.080\n",
            "[94,  2000] loss: 0.036\n",
            "[94,  4000] loss: 0.067\n",
            "[94,  6000] loss: 0.066\n",
            "[94,  8000] loss: 0.083\n",
            "[94, 10000] loss: 0.055\n",
            "[94, 12000] loss: 0.075\n",
            "[95,  2000] loss: 0.097\n",
            "[95,  4000] loss: 0.062\n",
            "[95,  6000] loss: 0.079\n",
            "[95,  8000] loss: 0.084\n",
            "[95, 10000] loss: 0.084\n",
            "[95, 12000] loss: 0.082\n",
            "[96,  2000] loss: 0.055\n",
            "[96,  4000] loss: 0.061\n",
            "[96,  6000] loss: 0.087\n",
            "[96,  8000] loss: 0.084\n",
            "[96, 10000] loss: 0.064\n",
            "[96, 12000] loss: 0.088\n",
            "[97,  2000] loss: 0.070\n",
            "[97,  4000] loss: 0.045\n",
            "[97,  6000] loss: 0.091\n",
            "[97,  8000] loss: 0.042\n",
            "[97, 10000] loss: 0.063\n",
            "[97, 12000] loss: 0.102\n",
            "[98,  2000] loss: 0.086\n",
            "[98,  4000] loss: 0.055\n",
            "[98,  6000] loss: 0.105\n",
            "[98,  8000] loss: 0.135\n",
            "[98, 10000] loss: 0.112\n",
            "[98, 12000] loss: 0.080\n",
            "[99,  2000] loss: 0.052\n",
            "[99,  4000] loss: 0.040\n",
            "[99,  6000] loss: 0.064\n",
            "[99,  8000] loss: 0.066\n",
            "[99, 10000] loss: 0.068\n",
            "[99, 12000] loss: 0.138\n",
            "[100,  2000] loss: 0.074\n",
            "[100,  4000] loss: 0.085\n",
            "[100,  6000] loss: 0.072\n",
            "[100,  8000] loss: 0.121\n",
            "[100, 10000] loss: 0.098\n",
            "[100, 12000] loss: 0.110\n",
            "[101,  2000] loss: 0.071\n",
            "[101,  4000] loss: 0.058\n",
            "[101,  6000] loss: 0.065\n",
            "[101,  8000] loss: 0.102\n",
            "[101, 10000] loss: 0.090\n",
            "[101, 12000] loss: 0.075\n",
            "[102,  2000] loss: 0.041\n",
            "[102,  4000] loss: 0.070\n",
            "[102,  6000] loss: 0.070\n",
            "[102,  8000] loss: 0.117\n",
            "[102, 10000] loss: 0.065\n",
            "[102, 12000] loss: 0.079\n",
            "[103,  2000] loss: 0.075\n",
            "[103,  4000] loss: 0.080\n",
            "[103,  6000] loss: 0.107\n",
            "[103,  8000] loss: 0.102\n",
            "[103, 10000] loss: 0.087\n",
            "[103, 12000] loss: 0.087\n",
            "[104,  2000] loss: 0.067\n",
            "[104,  4000] loss: 0.070\n",
            "[104,  6000] loss: 0.082\n",
            "[104,  8000] loss: 0.119\n",
            "[104, 10000] loss: 0.096\n",
            "[104, 12000] loss: 0.091\n",
            "[105,  2000] loss: 0.075\n",
            "[105,  4000] loss: 0.083\n",
            "[105,  6000] loss: 0.084\n",
            "[105,  8000] loss: 0.060\n",
            "[105, 10000] loss: 0.124\n",
            "[105, 12000] loss: 0.122\n",
            "[106,  2000] loss: 0.078\n",
            "[106,  4000] loss: 0.099\n",
            "[106,  6000] loss: 0.160\n",
            "[106,  8000] loss: 0.101\n",
            "[106, 10000] loss: 0.118\n",
            "[106, 12000] loss: 0.110\n",
            "[107,  2000] loss: 0.057\n",
            "[107,  4000] loss: 0.076\n",
            "[107,  6000] loss: 0.075\n",
            "[107,  8000] loss: 0.093\n",
            "[107, 10000] loss: 0.085\n",
            "[107, 12000] loss: 0.091\n",
            "[108,  2000] loss: 0.055\n",
            "[108,  4000] loss: 0.085\n",
            "[108,  6000] loss: 0.113\n",
            "[108,  8000] loss: 0.083\n",
            "[108, 10000] loss: 0.123\n",
            "[108, 12000] loss: 0.098\n",
            "[109,  2000] loss: 0.129\n",
            "[109,  4000] loss: 0.110\n",
            "[109,  6000] loss: 0.128\n",
            "[109,  8000] loss: 0.143\n",
            "[109, 10000] loss: 0.118\n",
            "[109, 12000] loss: 0.091\n",
            "[110,  2000] loss: 0.092\n",
            "[110,  4000] loss: 0.111\n",
            "[110,  6000] loss: 0.093\n",
            "[110,  8000] loss: 0.054\n",
            "[110, 10000] loss: 0.097\n",
            "[110, 12000] loss: 0.119\n",
            "[111,  2000] loss: 0.062\n",
            "[111,  4000] loss: 0.126\n",
            "[111,  6000] loss: 0.127\n",
            "[111,  8000] loss: 0.110\n",
            "[111, 10000] loss: 0.149\n",
            "[111, 12000] loss: 0.165\n",
            "[112,  2000] loss: 0.114\n",
            "[112,  4000] loss: 0.135\n",
            "[112,  6000] loss: 0.086\n",
            "[112,  8000] loss: 0.114\n",
            "[112, 10000] loss: 0.114\n",
            "[112, 12000] loss: 0.139\n",
            "[113,  2000] loss: 0.121\n",
            "[113,  4000] loss: 0.128\n",
            "[113,  6000] loss: 0.147\n",
            "[113,  8000] loss: 0.164\n",
            "[113, 10000] loss: 0.163\n",
            "[113, 12000] loss: 0.139\n",
            "[114,  2000] loss: 0.106\n",
            "[114,  4000] loss: 0.101\n",
            "[114,  6000] loss: 0.127\n",
            "[114,  8000] loss: 0.151\n",
            "[114, 10000] loss: 0.098\n",
            "[114, 12000] loss: 0.136\n",
            "[115,  2000] loss: 0.094\n",
            "[115,  4000] loss: 0.130\n",
            "[115,  6000] loss: 0.113\n",
            "[115,  8000] loss: 0.099\n",
            "[115, 10000] loss: 0.127\n",
            "[115, 12000] loss: 0.145\n",
            "[116,  2000] loss: 0.154\n",
            "[116,  4000] loss: 0.137\n",
            "[116,  6000] loss: 0.107\n",
            "[116,  8000] loss: 0.098\n",
            "[116, 10000] loss: 0.126\n",
            "[116, 12000] loss: 0.182\n",
            "[117,  2000] loss: 0.084\n",
            "[117,  4000] loss: 0.085\n",
            "[117,  6000] loss: 0.134\n",
            "[117,  8000] loss: 0.144\n",
            "[117, 10000] loss: 0.098\n",
            "[117, 12000] loss: 0.158\n",
            "[118,  2000] loss: 0.113\n",
            "[118,  4000] loss: 0.126\n",
            "[118,  6000] loss: 0.196\n",
            "[118,  8000] loss: 0.146\n",
            "[118, 10000] loss: 0.082\n",
            "[118, 12000] loss: 0.156\n",
            "[119,  2000] loss: 0.087\n",
            "[119,  4000] loss: 0.117\n",
            "[119,  6000] loss: 0.134\n",
            "[119,  8000] loss: 0.092\n",
            "[119, 10000] loss: 0.123\n",
            "[119, 12000] loss: 0.119\n",
            "[120,  2000] loss: 0.058\n",
            "[120,  4000] loss: 0.190\n",
            "[120,  6000] loss: 0.152\n",
            "[120,  8000] loss: 0.152\n",
            "[120, 10000] loss: 0.135\n",
            "[120, 12000] loss: 0.174\n",
            "[121,  2000] loss: 0.095\n",
            "[121,  4000] loss: 0.114\n",
            "[121,  6000] loss: 0.177\n",
            "[121,  8000] loss: 0.108\n",
            "[121, 10000] loss: 0.158\n",
            "[121, 12000] loss: 0.145\n",
            "[122,  2000] loss: 0.124\n",
            "[122,  4000] loss: 0.138\n",
            "[122,  6000] loss: 0.208\n",
            "[122,  8000] loss: 0.154\n",
            "[122, 10000] loss: 0.184\n",
            "[122, 12000] loss: 0.226\n",
            "[123,  2000] loss: 0.219\n",
            "[123,  4000] loss: 0.220\n",
            "[123,  6000] loss: 0.193\n",
            "[123,  8000] loss: 0.196\n",
            "[123, 10000] loss: 0.132\n",
            "[123, 12000] loss: 0.176\n",
            "[124,  2000] loss: 0.075\n",
            "[124,  4000] loss: 0.087\n",
            "[124,  6000] loss: 0.081\n",
            "[124,  8000] loss: 0.113\n",
            "[124, 10000] loss: 0.152\n",
            "[124, 12000] loss: 0.118\n",
            "[125,  2000] loss: 0.143\n",
            "[125,  4000] loss: 0.099\n",
            "[125,  6000] loss: 0.188\n",
            "[125,  8000] loss: 0.122\n",
            "[125, 10000] loss: 0.147\n",
            "[125, 12000] loss: 0.184\n",
            "[126,  2000] loss: 0.101\n",
            "[126,  4000] loss: 0.224\n",
            "[126,  6000] loss: 0.171\n",
            "[126,  8000] loss: 0.188\n",
            "[126, 10000] loss: 0.212\n",
            "[126, 12000] loss: 0.158\n",
            "[127,  2000] loss: 0.145\n",
            "[127,  4000] loss: 0.135\n",
            "[127,  6000] loss: 0.210\n",
            "[127,  8000] loss: 0.200\n",
            "[127, 10000] loss: 0.276\n",
            "[127, 12000] loss: 0.195\n",
            "[128,  2000] loss: 0.225\n",
            "[128,  4000] loss: 0.161\n",
            "[128,  6000] loss: 0.264\n",
            "[128,  8000] loss: 0.208\n",
            "[128, 10000] loss: 0.202\n",
            "[128, 12000] loss: 0.229\n",
            "[129,  2000] loss: 0.105\n",
            "[129,  4000] loss: 0.208\n",
            "[129,  6000] loss: 0.195\n",
            "[129,  8000] loss: 0.197\n",
            "[129, 10000] loss: 0.153\n",
            "[129, 12000] loss: 0.191\n",
            "[130,  2000] loss: 0.107\n",
            "[130,  4000] loss: 0.180\n",
            "[130,  6000] loss: 0.178\n",
            "[130,  8000] loss: 0.177\n",
            "[130, 10000] loss: 0.139\n",
            "[130, 12000] loss: 0.270\n",
            "[131,  2000] loss: 0.169\n",
            "[131,  4000] loss: 0.138\n",
            "[131,  6000] loss: 0.162\n",
            "[131,  8000] loss: 0.244\n",
            "[131, 10000] loss: 0.192\n",
            "[131, 12000] loss: 0.272\n",
            "[132,  2000] loss: 0.255\n",
            "[132,  4000] loss: 0.317\n",
            "[132,  6000] loss: 0.222\n",
            "[132,  8000] loss: 0.317\n",
            "[132, 10000] loss: 0.351\n",
            "[132, 12000] loss: 0.341\n",
            "[133,  2000] loss: 0.311\n",
            "[133,  4000] loss: 0.364\n",
            "[133,  6000] loss: 0.315\n",
            "[133,  8000] loss: 0.269\n",
            "[133, 10000] loss: 0.387\n",
            "[133, 12000] loss: 0.316\n",
            "[134,  2000] loss: 0.240\n",
            "[134,  4000] loss: 0.214\n",
            "[134,  6000] loss: 0.182\n",
            "[134,  8000] loss: 0.312\n",
            "[134, 10000] loss: 0.226\n",
            "[134, 12000] loss: 0.293\n",
            "[135,  2000] loss: 0.229\n",
            "[135,  4000] loss: 0.206\n",
            "[135,  6000] loss: 0.177\n",
            "[135,  8000] loss: 0.237\n",
            "[135, 10000] loss: 0.292\n",
            "[135, 12000] loss: 0.343\n",
            "[136,  2000] loss: 0.306\n",
            "[136,  4000] loss: 0.275\n",
            "[136,  6000] loss: 0.237\n",
            "[136,  8000] loss: 0.248\n",
            "[136, 10000] loss: 0.322\n",
            "[136, 12000] loss: 0.206\n",
            "[137,  2000] loss: 0.296\n",
            "[137,  4000] loss: 0.261\n",
            "[137,  6000] loss: 0.305\n",
            "[137,  8000] loss: 0.449\n",
            "[137, 10000] loss: 0.410\n",
            "[137, 12000] loss: 0.350\n",
            "[138,  2000] loss: 0.372\n",
            "[138,  4000] loss: 0.333\n",
            "[138,  6000] loss: 0.311\n",
            "[138,  8000] loss: 0.260\n",
            "[138, 10000] loss: 0.303\n",
            "[138, 12000] loss: 0.385\n",
            "[139,  2000] loss: 0.480\n",
            "[139,  4000] loss: 0.389\n",
            "[139,  6000] loss: 0.372\n",
            "[139,  8000] loss: 0.361\n",
            "[139, 10000] loss: 0.460\n",
            "[139, 12000] loss: 0.447\n",
            "[140,  2000] loss: 0.289\n",
            "[140,  4000] loss: 0.356\n",
            "[140,  6000] loss: 0.348\n",
            "[140,  8000] loss: 0.360\n",
            "[140, 10000] loss: 0.489\n",
            "[140, 12000] loss: 0.438\n",
            "[141,  2000] loss: 0.392\n",
            "[141,  4000] loss: 0.478\n",
            "[141,  6000] loss: 0.407\n",
            "[141,  8000] loss: 0.491\n",
            "[141, 10000] loss: 0.497\n",
            "[141, 12000] loss: 0.380\n",
            "[142,  2000] loss: 0.403\n",
            "[142,  4000] loss: 0.409\n",
            "[142,  6000] loss: 0.558\n",
            "[142,  8000] loss: 0.355\n",
            "[142, 10000] loss: 0.639\n",
            "[142, 12000] loss: 0.513\n",
            "[143,  2000] loss: 0.592\n",
            "[143,  4000] loss: 0.432\n",
            "[143,  6000] loss: 0.473\n",
            "[143,  8000] loss: 0.867\n",
            "[143, 10000] loss: 0.541\n",
            "[143, 12000] loss: 0.550\n",
            "[144,  2000] loss: 0.436\n",
            "[144,  4000] loss: 0.464\n",
            "[144,  6000] loss: 0.671\n",
            "[144,  8000] loss: 0.451\n",
            "[144, 10000] loss: 0.790\n",
            "[144, 12000] loss: 0.885\n",
            "[145,  2000] loss: 0.577\n",
            "[145,  4000] loss: 0.558\n",
            "[145,  6000] loss: 0.459\n",
            "[145,  8000] loss: 0.404\n",
            "[145, 10000] loss: 0.545\n",
            "[145, 12000] loss: 0.542\n",
            "[146,  2000] loss: 0.613\n",
            "[146,  4000] loss: 0.654\n",
            "[146,  6000] loss: 0.606\n",
            "[146,  8000] loss: 0.528\n",
            "[146, 10000] loss: 0.726\n",
            "[146, 12000] loss: 0.813\n",
            "[147,  2000] loss: 0.699\n",
            "[147,  4000] loss: 1.078\n",
            "[147,  6000] loss: 1.121\n",
            "[147,  8000] loss: 0.955\n",
            "[147, 10000] loss: 0.961\n",
            "[147, 12000] loss: 0.904\n",
            "[148,  2000] loss: 0.746\n",
            "[148,  4000] loss: 0.705\n",
            "[148,  6000] loss: 0.608\n",
            "[148,  8000] loss: 0.668\n",
            "[148, 10000] loss: 0.770\n",
            "[148, 12000] loss: 1.008\n",
            "[149,  2000] loss: 0.821\n",
            "[149,  4000] loss: 0.741\n",
            "[149,  6000] loss: 0.811\n",
            "[149,  8000] loss: 0.847\n",
            "[149, 10000] loss: 0.794\n",
            "[149, 12000] loss: 0.737\n",
            "[150,  2000] loss: 1.034\n",
            "[150,  4000] loss: 0.749\n",
            "[150,  6000] loss: 0.864\n",
            "[150,  8000] loss: 0.837\n",
            "[150, 10000] loss: 1.053\n",
            "[150, 12000] loss: 0.732\n",
            "[151,  2000] loss: 1.154\n",
            "[151,  4000] loss: 1.429\n",
            "[151,  6000] loss: 1.346\n",
            "[151,  8000] loss: 1.368\n",
            "[151, 10000] loss: 1.285\n",
            "[151, 12000] loss: 1.149\n",
            "[152,  2000] loss: 0.909\n",
            "[152,  4000] loss: 0.889\n",
            "[152,  6000] loss: 0.871\n",
            "[152,  8000] loss: 0.935\n",
            "[152, 10000] loss: 1.281\n",
            "[152, 12000] loss: 1.464\n",
            "[153,  2000] loss: 1.157\n",
            "[153,  4000] loss: 1.078\n",
            "[153,  6000] loss: 1.235\n",
            "[153,  8000] loss: 1.454\n",
            "[153, 10000] loss: 1.611\n",
            "[153, 12000] loss: 1.426\n",
            "[154,  2000] loss: 1.625\n",
            "[154,  4000] loss: 1.867\n",
            "[154,  6000] loss: 1.631\n",
            "[154,  8000] loss: 1.677\n",
            "[154, 10000] loss: 1.697\n",
            "[154, 12000] loss: 1.963\n",
            "[155,  2000] loss: 1.794\n",
            "[155,  4000] loss: 1.915\n",
            "[155,  6000] loss: 1.890\n",
            "[155,  8000] loss: 1.893\n",
            "[155, 10000] loss: 2.099\n",
            "[155, 12000] loss: 2.077\n",
            "[156,  2000] loss: 2.092\n",
            "[156,  4000] loss: 2.192\n",
            "[156,  6000] loss: 2.133\n",
            "[156,  8000] loss: 2.062\n",
            "[156, 10000] loss: 1.957\n",
            "[156, 12000] loss: 1.825\n",
            "[157,  2000] loss: 1.824\n",
            "[157,  4000] loss: 1.786\n",
            "[157,  6000] loss: 1.994\n",
            "[157,  8000] loss: 1.929\n",
            "[157, 10000] loss: 1.909\n",
            "[157, 12000] loss: 1.940\n",
            "[158,  2000] loss: 1.948\n",
            "[158,  4000] loss: 1.866\n",
            "[158,  6000] loss: 2.105\n",
            "[158,  8000] loss: 1.866\n",
            "[158, 10000] loss: 1.923\n",
            "[158, 12000] loss: 2.208\n",
            "[159,  2000] loss: 2.051\n",
            "[159,  4000] loss: 2.020\n",
            "[159,  6000] loss: 2.154\n",
            "[159,  8000] loss: 2.155\n",
            "[159, 10000] loss: 2.004\n",
            "[159, 12000] loss: 2.308\n",
            "[160,  2000] loss: 2.112\n",
            "[160,  4000] loss: 2.079\n",
            "[160,  6000] loss: 2.069\n",
            "[160,  8000] loss: 2.124\n",
            "[160, 10000] loss: 2.061\n",
            "[160, 12000] loss: 1.866\n",
            "[161,  2000] loss: 1.896\n",
            "[161,  4000] loss: 1.878\n",
            "[161,  6000] loss: 2.024\n",
            "[161,  8000] loss: 1.859\n",
            "[161, 10000] loss: 2.101\n",
            "[161, 12000] loss: 2.016\n",
            "[162,  2000] loss: 1.985\n",
            "[162,  4000] loss: 1.816\n",
            "[162,  6000] loss: 1.931\n",
            "[162,  8000] loss: 2.091\n",
            "[162, 10000] loss: 2.035\n",
            "[162, 12000] loss: 2.133\n",
            "[163,  2000] loss: 2.311\n",
            "[163,  4000] loss: 2.327\n",
            "[163,  6000] loss: 2.266\n",
            "[163,  8000] loss: 2.264\n",
            "[163, 10000] loss: 2.252\n",
            "[163, 12000] loss: 2.201\n",
            "[164,  2000] loss: 2.273\n",
            "[164,  4000] loss: 2.185\n",
            "[164,  6000] loss: 2.304\n",
            "[164,  8000] loss: 2.261\n",
            "[164, 10000] loss: 2.164\n",
            "[164, 12000] loss: 2.150\n",
            "[165,  2000] loss: 2.072\n",
            "[165,  4000] loss: 2.212\n",
            "[165,  6000] loss: 2.185\n",
            "[165,  8000] loss: 2.102\n",
            "[165, 10000] loss: 2.291\n",
            "[165, 12000] loss: 2.243\n",
            "[166,  2000] loss: 2.248\n",
            "[166,  4000] loss: 2.222\n",
            "[166,  6000] loss: 2.268\n",
            "[166,  8000] loss: 2.252\n",
            "[166, 10000] loss: 2.278\n",
            "[166, 12000] loss: 2.294\n",
            "[167,  2000] loss: 2.278\n",
            "[167,  4000] loss: 2.265\n",
            "[167,  6000] loss: 2.251\n",
            "[167,  8000] loss: 2.147\n",
            "[167, 10000] loss: 2.181\n",
            "[167, 12000] loss: 2.184\n",
            "[168,  2000] loss: 2.190\n",
            "[168,  4000] loss: 2.268\n",
            "[168,  6000] loss: 2.330\n",
            "[168,  8000] loss: 2.336\n",
            "[168, 10000] loss: 2.249\n",
            "[168, 12000] loss: 2.173\n",
            "[169,  2000] loss: 2.015\n",
            "[169,  4000] loss: 2.138\n",
            "[169,  6000] loss: 2.063\n",
            "[169,  8000] loss: 2.118\n",
            "[169, 10000] loss: 2.209\n",
            "[169, 12000] loss: 2.105\n",
            "[170,  2000] loss: 1.989\n",
            "[170,  4000] loss: 2.180\n",
            "[170,  6000] loss: 2.230\n",
            "[170,  8000] loss: 2.185\n",
            "[170, 10000] loss: 2.165\n",
            "[170, 12000] loss: 2.357\n",
            "[171,  2000] loss: 2.332\n",
            "[171,  4000] loss: 2.300\n",
            "[171,  6000] loss: 2.303\n",
            "[171,  8000] loss: 2.301\n",
            "[171, 10000] loss: 2.301\n",
            "[171, 12000] loss: 2.333\n",
            "[172,  2000] loss: 2.300\n",
            "[172,  4000] loss: 2.300\n",
            "[172,  6000] loss: 2.299\n",
            "[172,  8000] loss: 2.300\n",
            "[172, 10000] loss: 2.299\n",
            "[172, 12000] loss: 2.301\n",
            "[173,  2000] loss: 2.297\n",
            "[173,  4000] loss: 2.298\n",
            "[173,  6000] loss: 2.299\n",
            "[173,  8000] loss: 2.299\n",
            "[173, 10000] loss: 2.298\n",
            "[173, 12000] loss: 2.297\n",
            "[174,  2000] loss: 2.291\n",
            "[174,  4000] loss: 2.298\n",
            "[174,  6000] loss: 2.292\n",
            "[174,  8000] loss: 2.301\n",
            "[174, 10000] loss: 2.301\n",
            "[174, 12000] loss: 2.296\n",
            "[175,  2000] loss: 2.287\n",
            "[175,  4000] loss: 2.317\n",
            "[175,  6000] loss: 2.300\n",
            "[175,  8000] loss: 2.303\n",
            "[175, 10000] loss: 2.292\n",
            "[175, 12000] loss: 2.292\n",
            "[176,  2000] loss: 2.286\n",
            "[176,  4000] loss: 2.289\n",
            "[176,  6000] loss: 2.286\n",
            "[176,  8000] loss: 2.269\n",
            "[176, 10000] loss: 2.275\n",
            "[176, 12000] loss: 2.284\n",
            "[177,  2000] loss: 2.250\n",
            "[177,  4000] loss: 2.252\n",
            "[177,  6000] loss: 2.351\n",
            "[177,  8000] loss: 2.284\n",
            "[177, 10000] loss: 2.322\n",
            "[177, 12000] loss: 2.292\n",
            "[178,  2000] loss: 2.275\n",
            "[178,  4000] loss: 2.266\n",
            "[178,  6000] loss: 2.272\n",
            "[178,  8000] loss: 2.250\n",
            "[178, 10000] loss: 2.291\n",
            "[178, 12000] loss: 2.258\n",
            "[179,  2000] loss: 2.227\n",
            "[179,  4000] loss: 2.207\n",
            "[179,  6000] loss: 2.240\n",
            "[179,  8000] loss: 2.217\n",
            "[179, 10000] loss: 2.247\n",
            "[179, 12000] loss: 2.240\n",
            "[180,  2000] loss: 2.251\n",
            "[180,  4000] loss: 2.273\n",
            "[180,  6000] loss: 2.254\n",
            "[180,  8000] loss: 2.214\n",
            "[180, 10000] loss: 2.289\n",
            "[180, 12000] loss: 2.278\n",
            "[181,  2000] loss: 2.234\n",
            "[181,  4000] loss: 2.202\n",
            "[181,  6000] loss: 2.202\n",
            "[181,  8000] loss: 2.259\n",
            "[181, 10000] loss: 2.239\n",
            "[181, 12000] loss: 2.301\n",
            "[182,  2000] loss: 2.303\n",
            "[182,  4000] loss: 2.303\n",
            "[182,  6000] loss: 2.304\n",
            "[182,  8000] loss: 2.303\n",
            "[182, 10000] loss: 2.304\n",
            "[182, 12000] loss: 2.303\n",
            "[183,  2000] loss: 2.303\n",
            "[183,  4000] loss: 2.302\n",
            "[183,  6000] loss: 2.303\n",
            "[183,  8000] loss: 2.303\n",
            "[183, 10000] loss: 2.303\n",
            "[183, 12000] loss: 2.304\n",
            "[184,  2000] loss: 2.303\n",
            "[184,  4000] loss: 2.303\n",
            "[184,  6000] loss: 2.303\n",
            "[184,  8000] loss: 2.303\n",
            "[184, 10000] loss: 2.303\n",
            "[184, 12000] loss: 2.303\n",
            "[185,  2000] loss: 2.303\n",
            "[185,  4000] loss: 2.303\n",
            "[185,  6000] loss: 2.303\n",
            "[185,  8000] loss: 2.303\n",
            "[185, 10000] loss: 2.303\n",
            "[185, 12000] loss: 2.303\n",
            "[186,  2000] loss: 2.303\n",
            "[186,  4000] loss: 2.303\n",
            "[186,  6000] loss: 2.303\n",
            "[186,  8000] loss: 2.303\n",
            "[186, 10000] loss: 2.303\n",
            "[186, 12000] loss: 2.303\n",
            "[187,  2000] loss: 2.303\n",
            "[187,  4000] loss: 2.303\n",
            "[187,  6000] loss: 2.304\n",
            "[187,  8000] loss: 2.303\n",
            "[187, 10000] loss: 2.303\n",
            "[187, 12000] loss: 2.303\n",
            "[188,  2000] loss: 2.303\n",
            "[188,  4000] loss: 2.303\n",
            "[188,  6000] loss: 2.303\n",
            "[188,  8000] loss: 2.303\n",
            "[188, 10000] loss: 2.303\n",
            "[188, 12000] loss: 2.303\n",
            "[189,  2000] loss: 2.303\n",
            "[189,  4000] loss: 2.303\n",
            "[189,  6000] loss: 2.303\n",
            "[189,  8000] loss: 2.303\n",
            "[189, 10000] loss: 2.303\n",
            "[189, 12000] loss: 2.303\n",
            "[190,  2000] loss: 2.302\n",
            "[190,  4000] loss: 2.303\n",
            "[190,  6000] loss: 2.303\n",
            "[190,  8000] loss: 2.303\n",
            "[190, 10000] loss: 2.303\n",
            "[190, 12000] loss: 2.303\n",
            "[191,  2000] loss: 2.303\n",
            "[191,  4000] loss: 2.303\n",
            "[191,  6000] loss: 2.304\n",
            "[191,  8000] loss: 2.303\n",
            "[191, 10000] loss: 2.303\n",
            "[191, 12000] loss: 2.303\n",
            "[192,  2000] loss: 2.303\n",
            "[192,  4000] loss: 2.303\n",
            "[192,  6000] loss: 2.303\n",
            "[192,  8000] loss: 2.303\n",
            "[192, 10000] loss: 2.303\n",
            "[192, 12000] loss: 2.304\n",
            "[193,  2000] loss: 2.303\n",
            "[193,  4000] loss: 2.303\n",
            "[193,  6000] loss: 2.303\n",
            "[193,  8000] loss: 2.303\n",
            "[193, 10000] loss: 2.303\n",
            "[193, 12000] loss: 2.303\n",
            "[194,  2000] loss: 2.303\n",
            "[194,  4000] loss: 2.303\n",
            "[194,  6000] loss: 2.303\n",
            "[194,  8000] loss: 2.303\n",
            "[194, 10000] loss: 2.303\n",
            "[194, 12000] loss: 2.303\n",
            "[195,  2000] loss: 2.303\n",
            "[195,  4000] loss: 2.303\n",
            "[195,  6000] loss: 2.303\n",
            "[195,  8000] loss: 2.303\n",
            "[195, 10000] loss: 2.303\n",
            "[195, 12000] loss: 2.303\n",
            "[196,  2000] loss: 2.303\n",
            "[196,  4000] loss: 2.303\n",
            "[196,  6000] loss: 2.303\n",
            "[196,  8000] loss: 2.303\n",
            "[196, 10000] loss: 2.303\n",
            "[196, 12000] loss: 2.303\n",
            "[197,  2000] loss: 2.303\n",
            "[197,  4000] loss: 2.303\n",
            "[197,  6000] loss: 2.303\n",
            "[197,  8000] loss: 2.303\n",
            "[197, 10000] loss: 2.303\n",
            "[197, 12000] loss: 2.303\n",
            "[198,  2000] loss: 2.302\n",
            "[198,  4000] loss: 2.304\n",
            "[198,  6000] loss: 2.303\n",
            "[198,  8000] loss: 2.303\n",
            "[198, 10000] loss: 2.303\n",
            "[198, 12000] loss: 2.303\n",
            "[199,  2000] loss: 2.303\n",
            "[199,  4000] loss: 2.303\n",
            "[199,  6000] loss: 2.303\n",
            "[199,  8000] loss: 2.303\n",
            "[199, 10000] loss: 2.303\n",
            "[199, 12000] loss: 2.303\n",
            "[200,  2000] loss: 2.303\n",
            "[200,  4000] loss: 2.303\n",
            "[200,  6000] loss: 2.303\n",
            "[200,  8000] loss: 2.303\n",
            "[200, 10000] loss: 2.303\n",
            "[200, 12000] loss: 2.303\n",
            "[201,  2000] loss: 2.303\n",
            "[201,  4000] loss: 2.303\n",
            "[201,  6000] loss: 2.303\n",
            "[201,  8000] loss: 2.303\n",
            "[201, 10000] loss: 2.303\n",
            "[201, 12000] loss: 2.303\n",
            "[202,  2000] loss: 2.303\n",
            "[202,  4000] loss: 2.303\n",
            "[202,  6000] loss: 2.303\n",
            "[202,  8000] loss: 2.303\n",
            "[202, 10000] loss: 2.303\n",
            "[202, 12000] loss: 2.303\n",
            "[203,  2000] loss: 2.303\n",
            "[203,  4000] loss: 2.304\n",
            "[203,  6000] loss: 2.303\n",
            "[203,  8000] loss: 2.303\n",
            "[203, 10000] loss: 2.303\n",
            "[203, 12000] loss: 2.303\n",
            "[204,  2000] loss: 2.303\n",
            "[204,  4000] loss: 2.303\n",
            "[204,  6000] loss: 2.303\n",
            "[204,  8000] loss: 2.303\n",
            "[204, 10000] loss: 2.303\n",
            "[204, 12000] loss: 2.303\n",
            "[205,  2000] loss: 2.303\n",
            "[205,  4000] loss: 2.303\n",
            "[205,  6000] loss: 2.303\n",
            "[205,  8000] loss: 2.303\n",
            "[205, 10000] loss: 2.303\n",
            "[205, 12000] loss: 2.303\n",
            "[206,  2000] loss: 2.303\n",
            "[206,  4000] loss: 2.303\n",
            "[206,  6000] loss: 2.303\n",
            "[206,  8000] loss: 2.303\n",
            "[206, 10000] loss: 2.303\n",
            "[206, 12000] loss: 2.303\n",
            "[207,  2000] loss: 2.303\n",
            "[207,  4000] loss: 2.303\n",
            "[207,  6000] loss: 2.303\n",
            "[207,  8000] loss: 2.303\n",
            "[207, 10000] loss: 2.303\n",
            "[207, 12000] loss: 2.302\n",
            "[208,  2000] loss: 2.304\n",
            "[208,  4000] loss: 2.304\n",
            "[208,  6000] loss: 2.303\n",
            "[208,  8000] loss: 2.303\n",
            "[208, 10000] loss: 2.303\n",
            "[208, 12000] loss: 2.303\n",
            "[209,  2000] loss: 2.303\n",
            "[209,  4000] loss: 2.303\n",
            "[209,  6000] loss: 2.303\n",
            "[209,  8000] loss: 2.303\n",
            "[209, 10000] loss: 2.303\n",
            "[209, 12000] loss: 2.303\n",
            "[210,  2000] loss: 2.303\n",
            "[210,  4000] loss: 2.302\n",
            "[210,  6000] loss: 2.304\n",
            "[210,  8000] loss: 2.303\n",
            "[210, 10000] loss: 2.303\n",
            "[210, 12000] loss: 2.303\n",
            "[211,  2000] loss: 2.303\n",
            "[211,  4000] loss: 2.303\n",
            "[211,  6000] loss: 2.303\n",
            "[211,  8000] loss: 2.303\n",
            "[211, 10000] loss: 2.303\n",
            "[211, 12000] loss: 2.303\n",
            "[212,  2000] loss: 2.303\n",
            "[212,  4000] loss: 2.303\n",
            "[212,  6000] loss: 2.303\n",
            "[212,  8000] loss: 2.303\n",
            "[212, 10000] loss: 2.303\n",
            "[212, 12000] loss: 2.303\n",
            "[213,  2000] loss: 2.303\n",
            "[213,  4000] loss: 2.303\n",
            "[213,  6000] loss: 2.303\n",
            "[213,  8000] loss: 2.303\n",
            "[213, 10000] loss: 2.304\n",
            "[213, 12000] loss: 2.303\n",
            "[214,  2000] loss: 2.303\n",
            "[214,  4000] loss: 2.303\n",
            "[214,  6000] loss: 2.303\n",
            "[214,  8000] loss: 2.303\n",
            "[214, 10000] loss: 2.303\n",
            "[214, 12000] loss: 2.303\n",
            "[215,  2000] loss: 2.303\n",
            "[215,  4000] loss: 2.303\n",
            "[215,  6000] loss: 2.304\n",
            "[215,  8000] loss: 2.303\n",
            "[215, 10000] loss: 2.303\n",
            "[215, 12000] loss: 2.303\n",
            "[216,  2000] loss: 2.304\n",
            "[216,  4000] loss: 2.303\n",
            "[216,  6000] loss: 2.303\n",
            "[216,  8000] loss: 2.303\n",
            "[216, 10000] loss: 2.303\n",
            "[216, 12000] loss: 2.303\n",
            "[217,  2000] loss: 2.303\n",
            "[217,  4000] loss: 2.303\n",
            "[217,  6000] loss: 2.303\n",
            "[217,  8000] loss: 2.303\n",
            "[217, 10000] loss: 2.303\n",
            "[217, 12000] loss: 2.303\n",
            "[218,  2000] loss: 2.303\n",
            "[218,  4000] loss: 2.303\n",
            "[218,  6000] loss: 2.303\n",
            "[218,  8000] loss: 2.303\n",
            "[218, 10000] loss: 2.303\n",
            "[218, 12000] loss: 2.303\n",
            "[219,  2000] loss: 2.303\n",
            "[219,  4000] loss: 2.303\n",
            "[219,  6000] loss: 2.303\n",
            "[219,  8000] loss: 2.303\n",
            "[219, 10000] loss: 2.303\n",
            "[219, 12000] loss: 2.303\n",
            "[220,  2000] loss: 2.303\n",
            "[220,  4000] loss: 2.303\n",
            "[220,  6000] loss: 2.303\n",
            "[220,  8000] loss: 2.303\n",
            "[220, 10000] loss: 2.303\n",
            "[220, 12000] loss: 2.303\n",
            "[221,  2000] loss: 2.303\n",
            "[221,  4000] loss: 2.303\n",
            "[221,  6000] loss: 2.303\n",
            "[221,  8000] loss: 2.303\n",
            "[221, 10000] loss: 2.303\n",
            "[221, 12000] loss: 2.303\n",
            "[222,  2000] loss: 2.303\n",
            "[222,  4000] loss: 2.303\n",
            "[222,  6000] loss: 2.303\n",
            "[222,  8000] loss: 2.303\n",
            "[222, 10000] loss: 2.303\n",
            "[222, 12000] loss: 2.303\n",
            "[223,  2000] loss: 2.302\n",
            "[223,  4000] loss: 2.303\n",
            "[223,  6000] loss: 2.303\n",
            "[223,  8000] loss: 2.303\n",
            "[223, 10000] loss: 2.304\n",
            "[223, 12000] loss: 2.303\n",
            "[224,  2000] loss: 2.303\n",
            "[224,  4000] loss: 2.303\n",
            "[224,  6000] loss: 2.303\n",
            "[224,  8000] loss: 2.303\n",
            "[224, 10000] loss: 2.303\n",
            "[224, 12000] loss: 2.303\n",
            "[225,  2000] loss: 2.303\n",
            "[225,  4000] loss: 2.303\n",
            "[225,  6000] loss: 2.304\n",
            "[225,  8000] loss: 2.303\n",
            "[225, 10000] loss: 2.304\n",
            "[225, 12000] loss: 2.303\n",
            "[226,  2000] loss: 2.303\n",
            "[226,  4000] loss: 2.303\n",
            "[226,  6000] loss: 2.303\n",
            "[226,  8000] loss: 2.303\n",
            "[226, 10000] loss: 2.303\n",
            "[226, 12000] loss: 2.303\n",
            "[227,  2000] loss: 2.303\n",
            "[227,  4000] loss: 2.303\n",
            "[227,  6000] loss: 2.303\n",
            "[227,  8000] loss: 2.303\n",
            "[227, 10000] loss: 2.303\n",
            "[227, 12000] loss: 2.303\n",
            "[228,  2000] loss: 2.303\n",
            "[228,  4000] loss: 2.303\n",
            "[228,  6000] loss: 2.303\n",
            "[228,  8000] loss: 2.303\n",
            "[228, 10000] loss: 2.303\n",
            "[228, 12000] loss: 2.303\n",
            "[229,  2000] loss: 2.303\n",
            "[229,  4000] loss: 2.303\n",
            "[229,  6000] loss: 2.303\n",
            "[229,  8000] loss: 2.303\n",
            "[229, 10000] loss: 2.303\n",
            "[229, 12000] loss: 2.303\n",
            "[230,  2000] loss: 2.303\n",
            "[230,  4000] loss: 2.303\n",
            "[230,  6000] loss: 2.303\n",
            "[230,  8000] loss: 2.303\n",
            "[230, 10000] loss: 2.303\n",
            "[230, 12000] loss: 2.303\n",
            "[231,  2000] loss: 2.303\n",
            "[231,  4000] loss: 2.303\n",
            "[231,  6000] loss: 2.303\n",
            "[231,  8000] loss: 2.303\n",
            "[231, 10000] loss: 2.303\n",
            "[231, 12000] loss: 2.303\n",
            "[232,  2000] loss: 2.303\n",
            "[232,  4000] loss: 2.303\n",
            "[232,  6000] loss: 2.303\n",
            "[232,  8000] loss: 2.303\n",
            "[232, 10000] loss: 2.303\n",
            "[232, 12000] loss: 2.303\n",
            "[233,  2000] loss: 2.303\n",
            "[233,  4000] loss: 2.303\n",
            "[233,  6000] loss: 2.303\n",
            "[233,  8000] loss: 2.303\n",
            "[233, 10000] loss: 2.303\n",
            "[233, 12000] loss: 2.303\n",
            "[234,  2000] loss: 2.303\n",
            "[234,  4000] loss: 2.303\n",
            "[234,  6000] loss: 2.303\n",
            "[234,  8000] loss: 2.304\n",
            "[234, 10000] loss: 2.303\n",
            "[234, 12000] loss: 2.304\n",
            "[235,  2000] loss: 2.304\n",
            "[235,  4000] loss: 2.303\n",
            "[235,  6000] loss: 2.303\n",
            "[235,  8000] loss: 2.303\n",
            "[235, 10000] loss: 2.303\n",
            "[235, 12000] loss: 2.303\n",
            "[236,  2000] loss: 2.303\n",
            "[236,  4000] loss: 2.303\n",
            "[236,  6000] loss: 2.303\n",
            "[236,  8000] loss: 2.303\n",
            "[236, 10000] loss: 2.303\n",
            "[236, 12000] loss: 2.303\n",
            "[237,  2000] loss: 2.303\n",
            "[237,  4000] loss: 2.303\n",
            "[237,  6000] loss: 2.303\n",
            "[237,  8000] loss: 2.303\n",
            "[237, 10000] loss: 2.303\n",
            "[237, 12000] loss: 2.303\n",
            "[238,  2000] loss: 2.303\n",
            "[238,  4000] loss: 2.303\n",
            "[238,  6000] loss: 2.303\n",
            "[238,  8000] loss: 2.303\n",
            "[238, 10000] loss: 2.303\n",
            "[238, 12000] loss: 2.303\n",
            "[239,  2000] loss: 2.303\n",
            "[239,  4000] loss: 2.303\n",
            "[239,  6000] loss: 2.303\n",
            "[239,  8000] loss: 2.303\n",
            "[239, 10000] loss: 2.304\n",
            "[239, 12000] loss: 2.303\n",
            "[240,  2000] loss: 2.303\n",
            "[240,  4000] loss: 2.303\n",
            "[240,  6000] loss: 2.303\n",
            "[240,  8000] loss: 2.303\n",
            "[240, 10000] loss: 2.303\n",
            "[240, 12000] loss: 2.303\n",
            "[241,  2000] loss: 2.303\n",
            "[241,  4000] loss: 2.303\n",
            "[241,  6000] loss: 2.303\n",
            "[241,  8000] loss: 2.303\n",
            "[241, 10000] loss: 2.303\n",
            "[241, 12000] loss: 2.303\n",
            "[242,  2000] loss: 2.303\n",
            "[242,  4000] loss: 2.304\n",
            "[242,  6000] loss: 2.303\n",
            "[242,  8000] loss: 2.303\n",
            "[242, 10000] loss: 2.303\n",
            "[242, 12000] loss: 2.303\n",
            "[243,  2000] loss: 2.303\n",
            "[243,  4000] loss: 2.303\n",
            "[243,  6000] loss: 2.303\n",
            "[243,  8000] loss: 2.303\n",
            "[243, 10000] loss: 2.303\n",
            "[243, 12000] loss: 2.303\n",
            "[244,  2000] loss: 2.303\n",
            "[244,  4000] loss: 2.303\n",
            "[244,  6000] loss: 2.303\n",
            "[244,  8000] loss: 2.303\n",
            "[244, 10000] loss: 2.303\n",
            "[244, 12000] loss: 2.303\n",
            "[245,  2000] loss: 2.303\n",
            "[245,  4000] loss: 2.303\n",
            "[245,  6000] loss: 2.303\n",
            "[245,  8000] loss: 2.303\n",
            "[245, 10000] loss: 2.303\n",
            "[245, 12000] loss: 2.303\n",
            "[246,  2000] loss: 2.303\n",
            "[246,  4000] loss: 2.303\n",
            "[246,  6000] loss: 2.303\n",
            "[246,  8000] loss: 2.303\n",
            "[246, 10000] loss: 2.303\n",
            "[246, 12000] loss: 2.303\n",
            "[247,  2000] loss: 2.303\n",
            "[247,  4000] loss: 2.303\n",
            "[247,  6000] loss: 2.303\n",
            "[247,  8000] loss: 2.303\n",
            "[247, 10000] loss: 2.303\n",
            "[247, 12000] loss: 2.303\n",
            "[248,  2000] loss: 2.303\n",
            "[248,  4000] loss: 2.303\n",
            "[248,  6000] loss: 2.303\n",
            "[248,  8000] loss: 2.303\n",
            "[248, 10000] loss: 2.303\n",
            "[248, 12000] loss: 2.303\n",
            "[249,  2000] loss: 2.303\n",
            "[249,  4000] loss: 2.303\n",
            "[249,  6000] loss: 2.304\n",
            "[249,  8000] loss: 2.303\n",
            "[249, 10000] loss: 2.303\n",
            "[249, 12000] loss: 2.303\n",
            "[250,  2000] loss: 2.303\n",
            "[250,  4000] loss: 2.303\n",
            "[250,  6000] loss: 2.303\n",
            "[250,  8000] loss: 2.303\n",
            "[250, 10000] loss: 2.303\n",
            "[250, 12000] loss: 2.303\n",
            "[251,  2000] loss: 2.303\n",
            "[251,  4000] loss: 2.303\n",
            "[251,  6000] loss: 2.304\n",
            "[251,  8000] loss: 2.303\n",
            "[251, 10000] loss: 2.303\n",
            "[251, 12000] loss: 2.303\n",
            "[252,  2000] loss: 2.303\n",
            "[252,  4000] loss: 2.303\n",
            "[252,  6000] loss: 2.303\n",
            "[252,  8000] loss: 2.304\n",
            "[252, 10000] loss: 2.303\n",
            "[252, 12000] loss: 2.303\n",
            "[253,  2000] loss: 2.303\n",
            "[253,  4000] loss: 2.303\n",
            "[253,  6000] loss: 2.303\n",
            "[253,  8000] loss: 2.303\n",
            "[253, 10000] loss: 2.303\n",
            "[253, 12000] loss: 2.303\n",
            "[254,  2000] loss: 2.303\n",
            "[254,  4000] loss: 2.303\n",
            "[254,  6000] loss: 2.303\n",
            "[254,  8000] loss: 2.303\n",
            "[254, 10000] loss: 2.303\n",
            "[254, 12000] loss: 2.303\n",
            "[255,  2000] loss: 2.303\n",
            "[255,  4000] loss: 2.303\n",
            "[255,  6000] loss: 2.303\n",
            "[255,  8000] loss: 2.303\n",
            "[255, 10000] loss: 2.303\n",
            "[255, 12000] loss: 2.303\n",
            "[256,  2000] loss: 2.304\n",
            "[256,  4000] loss: 2.303\n",
            "[256,  6000] loss: 2.303\n",
            "[256,  8000] loss: 2.303\n",
            "[256, 10000] loss: 2.303\n",
            "[256, 12000] loss: 2.303\n",
            "[257,  2000] loss: 2.303\n",
            "[257,  4000] loss: 2.303\n",
            "[257,  6000] loss: 2.303\n",
            "[257,  8000] loss: 2.303\n",
            "[257, 10000] loss: 2.303\n",
            "[257, 12000] loss: 2.303\n",
            "[258,  2000] loss: 2.303\n",
            "[258,  4000] loss: 2.303\n",
            "[258,  6000] loss: 2.303\n",
            "[258,  8000] loss: 2.303\n",
            "[258, 10000] loss: 2.303\n",
            "[258, 12000] loss: 2.303\n",
            "[259,  2000] loss: 2.303\n",
            "[259,  4000] loss: 2.303\n",
            "[259,  6000] loss: 2.303\n",
            "[259,  8000] loss: 2.303\n",
            "[259, 10000] loss: 2.303\n",
            "[259, 12000] loss: 2.304\n",
            "[260,  2000] loss: 2.303\n",
            "[260,  4000] loss: 2.303\n",
            "[260,  6000] loss: 2.304\n",
            "[260,  8000] loss: 2.303\n",
            "[260, 10000] loss: 2.303\n",
            "[260, 12000] loss: 2.303\n",
            "[261,  2000] loss: 2.303\n",
            "[261,  4000] loss: 2.303\n",
            "[261,  6000] loss: 2.303\n",
            "[261,  8000] loss: 2.303\n",
            "[261, 10000] loss: 2.303\n",
            "[261, 12000] loss: 2.303\n",
            "[262,  2000] loss: 2.303\n",
            "[262,  4000] loss: 2.303\n",
            "[262,  6000] loss: 2.303\n",
            "[262,  8000] loss: 2.303\n",
            "[262, 10000] loss: 2.303\n",
            "[262, 12000] loss: 2.303\n",
            "[263,  2000] loss: 2.303\n",
            "[263,  4000] loss: 2.303\n",
            "[263,  6000] loss: 2.303\n",
            "[263,  8000] loss: 2.303\n",
            "[263, 10000] loss: 2.303\n",
            "[263, 12000] loss: 2.303\n",
            "[264,  2000] loss: 2.303\n",
            "[264,  4000] loss: 2.303\n",
            "[264,  6000] loss: 2.303\n",
            "[264,  8000] loss: 2.303\n",
            "[264, 10000] loss: 2.303\n",
            "[264, 12000] loss: 2.303\n",
            "[265,  2000] loss: 2.303\n",
            "[265,  4000] loss: 2.303\n",
            "[265,  6000] loss: 2.303\n",
            "[265,  8000] loss: 2.303\n",
            "[265, 10000] loss: 2.303\n",
            "[265, 12000] loss: 2.303\n",
            "[266,  2000] loss: 2.303\n",
            "[266,  4000] loss: 2.303\n",
            "[266,  6000] loss: 2.303\n",
            "[266,  8000] loss: 2.303\n",
            "[266, 10000] loss: 2.303\n",
            "[266, 12000] loss: 2.303\n",
            "[267,  2000] loss: 2.303\n",
            "[267,  4000] loss: 2.303\n",
            "[267,  6000] loss: 2.304\n",
            "[267,  8000] loss: 2.303\n",
            "[267, 10000] loss: 2.303\n",
            "[267, 12000] loss: 2.303\n",
            "[268,  2000] loss: 2.303\n",
            "[268,  4000] loss: 2.303\n",
            "[268,  6000] loss: 2.303\n",
            "[268,  8000] loss: 2.303\n",
            "[268, 10000] loss: 2.303\n",
            "[268, 12000] loss: 2.302\n",
            "[269,  2000] loss: 2.303\n",
            "[269,  4000] loss: 2.303\n",
            "[269,  6000] loss: 2.303\n",
            "[269,  8000] loss: 2.303\n",
            "[269, 10000] loss: 2.303\n",
            "[269, 12000] loss: 2.303\n",
            "[270,  2000] loss: 2.303\n",
            "[270,  4000] loss: 2.303\n",
            "[270,  6000] loss: 2.303\n",
            "[270,  8000] loss: 2.303\n",
            "[270, 10000] loss: 2.303\n",
            "[270, 12000] loss: 2.303\n",
            "[271,  2000] loss: 2.303\n",
            "[271,  4000] loss: 2.303\n",
            "[271,  6000] loss: 2.303\n",
            "[271,  8000] loss: 2.303\n",
            "[271, 10000] loss: 2.303\n",
            "[271, 12000] loss: 2.302\n",
            "[272,  2000] loss: 2.303\n",
            "[272,  4000] loss: 2.303\n",
            "[272,  6000] loss: 2.303\n",
            "[272,  8000] loss: 2.303\n",
            "[272, 10000] loss: 2.303\n",
            "[272, 12000] loss: 2.303\n",
            "[273,  2000] loss: 2.303\n",
            "[273,  4000] loss: 2.303\n",
            "[273,  6000] loss: 2.303\n",
            "[273,  8000] loss: 2.303\n",
            "[273, 10000] loss: 2.303\n",
            "[273, 12000] loss: 2.303\n",
            "[274,  2000] loss: 2.303\n",
            "[274,  4000] loss: 2.303\n",
            "[274,  6000] loss: 2.303\n",
            "[274,  8000] loss: 2.303\n",
            "[274, 10000] loss: 2.303\n",
            "[274, 12000] loss: 2.303\n",
            "[275,  2000] loss: 2.303\n",
            "[275,  4000] loss: 2.303\n",
            "[275,  6000] loss: 2.303\n",
            "[275,  8000] loss: 2.303\n",
            "[275, 10000] loss: 2.303\n",
            "[275, 12000] loss: 2.303\n",
            "[276,  2000] loss: 2.304\n",
            "[276,  4000] loss: 2.302\n",
            "[276,  6000] loss: 2.304\n",
            "[276,  8000] loss: 2.303\n",
            "[276, 10000] loss: 2.303\n",
            "[276, 12000] loss: 2.303\n",
            "[277,  2000] loss: 2.303\n",
            "[277,  4000] loss: 2.303\n",
            "[277,  6000] loss: 2.303\n",
            "[277,  8000] loss: 2.303\n",
            "[277, 10000] loss: 2.303\n",
            "[277, 12000] loss: 2.303\n",
            "[278,  2000] loss: 2.303\n",
            "[278,  4000] loss: 2.303\n",
            "[278,  6000] loss: 2.303\n",
            "[278,  8000] loss: 2.302\n",
            "[278, 10000] loss: 2.303\n",
            "[278, 12000] loss: 2.303\n",
            "[279,  2000] loss: 2.303\n",
            "[279,  4000] loss: 2.303\n",
            "[279,  6000] loss: 2.303\n",
            "[279,  8000] loss: 2.303\n",
            "[279, 10000] loss: 2.303\n",
            "[279, 12000] loss: 2.303\n",
            "[280,  2000] loss: 2.303\n",
            "[280,  4000] loss: 2.304\n",
            "[280,  6000] loss: 2.303\n",
            "[280,  8000] loss: 2.303\n",
            "[280, 10000] loss: 2.303\n",
            "[280, 12000] loss: 2.303\n",
            "[281,  2000] loss: 2.303\n",
            "[281,  4000] loss: 2.303\n",
            "[281,  6000] loss: 2.303\n",
            "[281,  8000] loss: 2.303\n",
            "[281, 10000] loss: 2.303\n",
            "[281, 12000] loss: 2.303\n",
            "[282,  2000] loss: 2.303\n",
            "[282,  4000] loss: 2.303\n",
            "[282,  6000] loss: 2.303\n",
            "[282,  8000] loss: 2.303\n",
            "[282, 10000] loss: 2.303\n",
            "[282, 12000] loss: 2.303\n",
            "[283,  2000] loss: 2.303\n",
            "[283,  4000] loss: 2.303\n",
            "[283,  6000] loss: 2.304\n",
            "[283,  8000] loss: 2.303\n",
            "[283, 10000] loss: 2.303\n",
            "[283, 12000] loss: 2.302\n",
            "[284,  2000] loss: 2.304\n",
            "[284,  4000] loss: 2.303\n",
            "[284,  6000] loss: 2.303\n",
            "[284,  8000] loss: 2.303\n",
            "[284, 10000] loss: 2.303\n",
            "[284, 12000] loss: 2.303\n",
            "[285,  2000] loss: 2.303\n",
            "[285,  4000] loss: 2.303\n",
            "[285,  6000] loss: 2.303\n",
            "[285,  8000] loss: 2.303\n",
            "[285, 10000] loss: 2.303\n",
            "[285, 12000] loss: 2.303\n",
            "[286,  2000] loss: 2.303\n",
            "[286,  4000] loss: 2.303\n",
            "[286,  6000] loss: 2.303\n",
            "[286,  8000] loss: 2.303\n",
            "[286, 10000] loss: 2.304\n",
            "[286, 12000] loss: 2.303\n",
            "[287,  2000] loss: 2.303\n",
            "[287,  4000] loss: 2.303\n",
            "[287,  6000] loss: 2.303\n",
            "[287,  8000] loss: 2.303\n",
            "[287, 10000] loss: 2.304\n",
            "[287, 12000] loss: 2.303\n",
            "[288,  2000] loss: 2.303\n",
            "[288,  4000] loss: 2.303\n",
            "[288,  6000] loss: 2.303\n",
            "[288,  8000] loss: 2.303\n",
            "[288, 10000] loss: 2.303\n",
            "[288, 12000] loss: 2.303\n",
            "[289,  2000] loss: 2.303\n",
            "[289,  4000] loss: 2.304\n",
            "[289,  6000] loss: 2.303\n",
            "[289,  8000] loss: 2.303\n",
            "[289, 10000] loss: 2.303\n",
            "[289, 12000] loss: 2.303\n",
            "[290,  2000] loss: 2.303\n",
            "[290,  4000] loss: 2.303\n",
            "[290,  6000] loss: 2.303\n",
            "[290,  8000] loss: 2.303\n",
            "[290, 10000] loss: 2.303\n",
            "[290, 12000] loss: 2.302\n",
            "[291,  2000] loss: 2.303\n",
            "[291,  4000] loss: 2.303\n",
            "[291,  6000] loss: 2.303\n",
            "[291,  8000] loss: 2.303\n",
            "[291, 10000] loss: 2.303\n",
            "[291, 12000] loss: 2.303\n",
            "[292,  2000] loss: 2.303\n",
            "[292,  4000] loss: 2.303\n",
            "[292,  6000] loss: 2.303\n",
            "[292,  8000] loss: 2.303\n",
            "[292, 10000] loss: 2.303\n",
            "[292, 12000] loss: 2.303\n",
            "[293,  2000] loss: 2.303\n",
            "[293,  4000] loss: 2.303\n",
            "[293,  6000] loss: 2.303\n",
            "[293,  8000] loss: 2.303\n",
            "[293, 10000] loss: 2.303\n",
            "[293, 12000] loss: 2.303\n",
            "[294,  2000] loss: 2.303\n",
            "[294,  4000] loss: 2.303\n",
            "[294,  6000] loss: 2.303\n",
            "[294,  8000] loss: 2.303\n",
            "[294, 10000] loss: 2.303\n",
            "[294, 12000] loss: 2.304\n",
            "[295,  2000] loss: 2.303\n",
            "[295,  4000] loss: 2.303\n",
            "[295,  6000] loss: 2.303\n",
            "[295,  8000] loss: 2.303\n",
            "[295, 10000] loss: 2.303\n",
            "[295, 12000] loss: 2.303\n",
            "[296,  2000] loss: 2.303\n",
            "[296,  4000] loss: 2.303\n",
            "[296,  6000] loss: 2.303\n",
            "[296,  8000] loss: 2.303\n",
            "[296, 10000] loss: 2.303\n",
            "[296, 12000] loss: 2.303\n",
            "[297,  2000] loss: 2.303\n",
            "[297,  4000] loss: 2.303\n",
            "[297,  6000] loss: 2.303\n",
            "[297,  8000] loss: 2.303\n",
            "[297, 10000] loss: 2.303\n",
            "[297, 12000] loss: 2.303\n",
            "[298,  2000] loss: 2.303\n",
            "[298,  4000] loss: 2.303\n",
            "[298,  6000] loss: 2.303\n",
            "[298,  8000] loss: 2.303\n",
            "[298, 10000] loss: 2.303\n",
            "[298, 12000] loss: 2.303\n",
            "[299,  2000] loss: 2.303\n",
            "[299,  4000] loss: 2.303\n",
            "[299,  6000] loss: 2.303\n",
            "[299,  8000] loss: 2.303\n",
            "[299, 10000] loss: 2.303\n",
            "[299, 12000] loss: 2.303\n",
            "[300,  2000] loss: 2.303\n",
            "[300,  4000] loss: 2.303\n",
            "[300,  6000] loss: 2.303\n",
            "[300,  8000] loss: 2.303\n",
            "[300, 10000] loss: 2.303\n",
            "[300, 12000] loss: 2.303\n",
            "Finished Training\n",
            "Training time: 32581.27 seconds\n",
            "Accuracy of the network on the 10000 test images: 10.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n"
      ],
      "metadata": {
        "id": "ey1WYPE2aWTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, use_dropout=False):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.dropout = nn.Dropout(0.3) if use_dropout else nn.Identity()\n",
        "\n",
        "        self.skip = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.skip = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.dropout(out)\n",
        "        out += self.skip(identity)\n",
        "        return torch.relu(out)\n",
        "\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, dropout_rate=0):\n",
        "        super(ResNet10, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layers = self._make_layers(block, 64, num_blocks, stride=1, dropout_rate=dropout_rate)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layers(self, block, out_channels, num_blocks, stride, dropout_rate):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride, dropout_rate))\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layers(out)\n",
        "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "wVNE-6DnaYRT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10(cifar10_dir, batch_size=128):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root=cifar10_dir, train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root=cifar10_dir, train=False, download=True, transform=transform)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n"
      ],
      "metadata": {
        "id": "Rk4_98n2abj-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(trainloader)\n",
        "\n",
        "def evaluate(model, testloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n"
      ],
      "metadata": {
        "id": "mA1nXw-zmakp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    epochs = 300\n",
        "    cifar10_dir = r\"C:\\Users\\lfune\\Downloads\\cifar-10-batches-py\"  # Your CIFAR-10 directory\n",
        "    trainloader, testloader = load_cifar10(cifar10_dir)\n",
        "\n",
        "    # Regular training\n",
        "    model = ResNet10(ResNetBlock, 10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train(model, trainloader, criterion, optimizer, device)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    accuracy = evaluate(model, testloader, device)\n",
        "    print(f\"Regular Training - Loss: {train_loss:.4f}, Accuracy: {accuracy:.2f}%, Time: {training_time:.2f}s\")\n",
        "\n",
        "    # Regularization techniques: Weight Decay, Dropout, Batch Normalization\n",
        "    for weight_decay, dropout_rate in [(0.001, 0), (0, 0.3), (0, 0)]:\n",
        "        model = ResNet10(ResNetBlock, 10, dropout_rate=dropout_rate).to(device)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=weight_decay)\n",
        "        start_time = time.time()\n",
        "        for epoch in range(epochs):\n",
        "            train_loss = train(model, trainloader, criterion, optimizer, device)\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        accuracy = evaluate(model, testloader, device)\n",
        "        print(f\"Training with WD: {weight_decay}, Dropout: {dropout_rate} - Loss: {train_loss:.4f}, Accuracy: {accuracy:.2f}%, Time: {training_time:.2f}s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "twUGqu0ImoUM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0e52354b-716f-4166-f979-8e1e4d96ab8d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-90725a26368e>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-90725a26368e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-8418104f2ac3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}